{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "french-to-english-translator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cWmlTE5dmkT"
      },
      "source": [
        "# French to English Translator using Deep Learning\n",
        "This project aims to build a French to English translator using an artificial Recurrent Neural Network (RNN) called Long Short-Term Memory (LSTM)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0MAiXgYbAVLU",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "source": [
        "%%capture\n",
        "# install Tensorflow\n",
        "!pip install tensorflow \n",
        "\n",
        "# Loading spacy's French and English languages \n",
        "!pip install -U spacy\n",
        "!python -m spacy download fr_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2qUhyNPnhBtk",
        "outputId": "1dc3e97b-682c-4e19-ed97-5a3fbfd2bcf5"
      },
      "source": [
        "# Import required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import fr_core_news_sm\n",
        "import en_core_web_sm\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRgDaL6KdmkZ"
      },
      "source": [
        "### Importing data \n",
        "\n",
        "The data comes from a `.txt` file containing more than 160000 sentences with their translation separated by a tab (`\\t`).\n",
        "\n",
        "The data can be found on this link: https://go.aws/38ECHUB\n",
        "\n",
        "For performance purposes, we will not take the whole dataset but a sample of 5000 sentences instead. This will allow us to faster iterate and avoid bugs related to our need for computer power."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "Yj34GLiihGw1",
        "outputId": "8ca97e8e-35a8-4786-f4fb-eef4a58c0238"
      },
      "source": [
        "# Loading data\n",
        "doc = pd.read_csv(\"https://go.aws/38ECHUB\", delimiter=\"\\t\", header=None)\n",
        "doc.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>Ça alors !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0           1\n",
              "0   Go.        Va !\n",
              "1   Hi.     Salut !\n",
              "2  Run!     Cours !\n",
              "3  Run!    Courez !\n",
              "4  Wow!  Ça alors !"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT9RiXtbdmka",
        "outputId": "32b520f1-dcd9-4755-c7d1-f294698bdcc7"
      },
      "source": [
        "doc.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160538, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrcFSfBZMuQ7"
      },
      "source": [
        "# Let's just take a sample of 5000 sentences to avoid slowness\n",
        "doc = doc.sample(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O4hj8DGoFzr"
      },
      "source": [
        "# Loading of the entire corpus of French and English sentences\n",
        "fr_corpus = \" \".join(doc.iloc[:, 1].to_list())\n",
        "en_corpus = \" \".join(doc.iloc[:, 0].to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX1yEVxodmkb"
      },
      "source": [
        "### Preprocessing \n",
        "\n",
        "The main purpose of the preprocessing step is to express each French entry sentence in a sequence of clues.\n",
        "\n",
        "i.e.:\n",
        "\n",
        "* I'm sick ---> $[123, 21, 34, 0, 0, 0, 0, 0]$\n",
        "\n",
        "This gives a *shape* -> `(batch_size, max_len_of_a_sentence)`.\n",
        "\n",
        "The clues correspond to a number that we will have to assign for each word token. \n",
        "\n",
        "The zeros correspond to what are called [*padded_sequences*](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) which allow all word sequences to have the same length (mandatory for our algorithm). \n",
        "\n",
        "The transformation of our target sentences will not be exactly the same as that of our input sentences. In addition to all the steps we will have performed for the input sentences, we will also have to *categorize* our target sentences. In other words, an example tensor would look like : \n",
        "\n",
        "* I am sick ---> $\\begin{bmatrix} 1&0&0&...&0&0 \\\\ 0&0&0&...&1&0 \\\\ ... \\\\ 0&1&0&...&0&0 \\end{bmatrix}$\n",
        "\n",
        "This gives a *shape* -> `(batch_size, max_len_of_an_english_sentence, num_of_classes)`.\n",
        "\n",
        "To do this, we are going to use : \n",
        "\n",
        "* `Spacy` for Tokenization \n",
        "* `Tensorflow` for [padded_sequence](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) & [categorization](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical?hl=en)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPzvDSUWoWfW"
      },
      "source": [
        "# Loading both corpora into spacy \n",
        "nlp_fr = fr_core_news_sm.load()\n",
        "nlp_fr.max_length = len(fr_corpus)\n",
        "\n",
        "nlp_en = en_core_web_sm.load()\n",
        "nlp_en.max_length = len(en_corpus)\n",
        "\n",
        "fr_doc = nlp_fr(fr_corpus)\n",
        "en_doc = nlp_en(en_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBu43uJ77Ad6"
      },
      "source": [
        "# Tokenization of each sentence via spacy \n",
        "doc[\"fr_tokens\"] = doc.iloc[:, 1].apply(nlp_fr.tokenizer)\n",
        "doc[\"en_tokens\"] = doc.iloc[:, 0].apply(nlp_en.tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "bQQOU7OI7-xV",
        "outputId": "25949e3b-38bc-468f-bd14-e2a29a990a0a"
      },
      "source": [
        "doc.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>fr_tokens</th>\n",
              "      <th>en_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57172</th>\n",
              "      <td>I really did learn a lot.</td>\n",
              "      <td>J'ai vraiment beaucoup appris.</td>\n",
              "      <td>(J', ai, vraiment, beaucoup, appris, .)</td>\n",
              "      <td>(I, really, did, learn, a, lot, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65736</th>\n",
              "      <td>That'll cost thirty euros.</td>\n",
              "      <td>Ça va faire 30 euros.</td>\n",
              "      <td>(Ça, va, faire, 30, euros, .)</td>\n",
              "      <td>(That, 'll, cost, thirty, euros, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9139</th>\n",
              "      <td>You lied to me.</td>\n",
              "      <td>Vous m'avez menti.</td>\n",
              "      <td>(Vous, m', avez, menti, .)</td>\n",
              "      <td>(You, lied, to, me, .)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56290</th>\n",
              "      <td>How was the French class?</td>\n",
              "      <td>Comment s'est passé le cours de français ?</td>\n",
              "      <td>(Comment, s', est, passé, le, cours, de, franç...</td>\n",
              "      <td>(How, was, the, French, class, ?)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88048</th>\n",
              "      <td>I excused myself for a minute.</td>\n",
              "      <td>Je m'excusai pour une minute.</td>\n",
              "      <td>(Je, m', excusai, pour, une, minute, .)</td>\n",
              "      <td>(I, excused, myself, for, a, minute, .)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    0  ...                                en_tokens\n",
              "57172       I really did learn a lot.  ...       (I, really, did, learn, a, lot, .)\n",
              "65736      That'll cost thirty euros.  ...      (That, 'll, cost, thirty, euros, .)\n",
              "9139                  You lied to me.  ...                   (You, lied, to, me, .)\n",
              "56290       How was the French class?  ...        (How, was, the, French, class, ?)\n",
              "88048  I excused myself for a minute.  ...  (I, excused, myself, for, a, minute, .)\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwCN5z21xo5H",
        "outputId": "c05154d2-4d97-4e7a-f318-6ce5809f1644"
      },
      "source": [
        "# Creation of a set() that will take all the unique tokens from our text corpus\n",
        "en_tokens = [token.text for token in en_doc]\n",
        "en_vocabulary_set= set(en_tokens)\n",
        "en_vocab_size = len(en_vocabulary_set)\n",
        "print(en_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIwlGhNDykzn",
        "outputId": "551aa882-f522-4337-a4cb-abf34dc03910"
      },
      "source": [
        "# Same thing for French\n",
        "fr_tokens = [token.text for token in fr_doc]\n",
        "fr_vocabulary_set= set(fr_tokens)\n",
        "fr_vocab_size = len(fr_vocabulary_set)\n",
        "print(fr_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy_ou60_3X4X"
      },
      "source": [
        "# Creation of an id for each token\n",
        "all_en_tokens = {en_token: i + 1 for i, en_token in enumerate(en_vocabulary_set)}\n",
        "all_fr_tokens = {fr_token: i + 1 for i, fr_token in enumerate(fr_vocabulary_set)}\n",
        "# RQ: We take at i+1 to leave the value 0 for the creation of the padded_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIfUb1i7ia3"
      },
      "source": [
        "# Creation of functions that will create a vector of indices for each of the token sequences\n",
        "def en_tokens_to_index(tokens):\n",
        "    return [all_en_tokens[token.text] for token in tokens]\n",
        "\n",
        "def fr_tokens_to_index(tokens):\n",
        "    return [all_fr_tokens[token.text] for token in tokens]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA8Gc2Yw9abI"
      },
      "source": [
        "# Transformation of tokens into indices\n",
        "doc[\"fr_indices\"] = doc[\"fr_tokens\"].apply(fr_tokens_to_index)\n",
        "doc[\"en_indices\"] = doc[\"en_tokens\"].apply(en_tokens_to_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "rIWHfQsj-Yn8",
        "outputId": "d8260b6d-71b1-442a-e9a8-c1b98ce82c69"
      },
      "source": [
        "doc.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>fr_tokens</th>\n",
              "      <th>en_tokens</th>\n",
              "      <th>fr_indices</th>\n",
              "      <th>en_indices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57172</th>\n",
              "      <td>I really did learn a lot.</td>\n",
              "      <td>J'ai vraiment beaucoup appris.</td>\n",
              "      <td>(J', ai, vraiment, beaucoup, appris, .)</td>\n",
              "      <td>(I, really, did, learn, a, lot, .)</td>\n",
              "      <td>[3661, 3937, 1529, 4311, 1921, 922]</td>\n",
              "      <td>[2895, 499, 1626, 501, 3025, 2788, 634]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65736</th>\n",
              "      <td>That'll cost thirty euros.</td>\n",
              "      <td>Ça va faire 30 euros.</td>\n",
              "      <td>(Ça, va, faire, 30, euros, .)</td>\n",
              "      <td>(That, 'll, cost, thirty, euros, .)</td>\n",
              "      <td>[661, 1296, 2442, 4375, 3675, 922]</td>\n",
              "      <td>[1391, 1022, 1234, 2580, 2609, 634]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9139</th>\n",
              "      <td>You lied to me.</td>\n",
              "      <td>Vous m'avez menti.</td>\n",
              "      <td>(Vous, m', avez, menti, .)</td>\n",
              "      <td>(You, lied, to, me, .)</td>\n",
              "      <td>[4221, 2467, 2609, 973, 922]</td>\n",
              "      <td>[102, 3233, 2053, 923, 634]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56290</th>\n",
              "      <td>How was the French class?</td>\n",
              "      <td>Comment s'est passé le cours de français ?</td>\n",
              "      <td>(Comment, s', est, passé, le, cours, de, franç...</td>\n",
              "      <td>(How, was, the, French, class, ?)</td>\n",
              "      <td>[993, 1151, 3969, 241, 2553, 484, 940, 55, 157...</td>\n",
              "      <td>[1814, 640, 203, 3121, 246, 304]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88048</th>\n",
              "      <td>I excused myself for a minute.</td>\n",
              "      <td>Je m'excusai pour une minute.</td>\n",
              "      <td>(Je, m', excusai, pour, une, minute, .)</td>\n",
              "      <td>(I, excused, myself, for, a, minute, .)</td>\n",
              "      <td>[191, 2467, 505, 3248, 1572, 3945, 922]</td>\n",
              "      <td>[2895, 859, 3188, 3096, 3025, 2835, 634]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    0  ...                                en_indices\n",
              "57172       I really did learn a lot.  ...   [2895, 499, 1626, 501, 3025, 2788, 634]\n",
              "65736      That'll cost thirty euros.  ...       [1391, 1022, 1234, 2580, 2609, 634]\n",
              "9139                  You lied to me.  ...               [102, 3233, 2053, 923, 634]\n",
              "56290       How was the French class?  ...          [1814, 640, 203, 3121, 246, 304]\n",
              "88048  I excused myself for a minute.  ...  [2895, 859, 3188, 3096, 3025, 2835, 634]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no1txYiTdmke"
      },
      "source": [
        "# Use of Keras to create token sequences of the same length\n",
        "padded_fr_indices = tf.keras.preprocessing.sequence.pad_sequences(doc[\"fr_indices\"], padding=\"post\")\n",
        "padded_en_indices = tf.keras.preprocessing.sequence.pad_sequences(doc[\"en_indices\"], padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38el3B3z3btO",
        "outputId": "8ec79f24-a3b3-435f-ba73-4f0d5df8645e"
      },
      "source": [
        "# Visualization of the shape of one of the tensors\n",
        "padded_fr_indices.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxb0-Nk5dmkf",
        "outputId": "747b1194-c4bf-4832-bc10-9763c2d05bb4"
      },
      "source": [
        "padded_en_indices.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnJC64G7dmkf"
      },
      "source": [
        "**RQ:** the maximum length of the english sentences (28) is different from the maximum length of the french sentences (27)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1-ZRkjydmkf",
        "outputId": "3b93a9eb-1af5-4076-9582-9e1cd2cf2409"
      },
      "source": [
        "doc[\"fr_indices\"].apply(len).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbs73CRXdmkf",
        "outputId": "6beaebd2-d0eb-4d11-fa35-6560ac27d7bf"
      },
      "source": [
        "doc[\"en_indices\"].apply(len).max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLNl-EZe2kub",
        "outputId": "dfc920b8-e700-43f5-d95e-86b7cea138cc"
      },
      "source": [
        "# Application of the categorization of the target variable \n",
        "binarized_en_indices = tf.keras.utils.to_categorical(padded_en_indices, num_classes=en_vocab_size+1)\n",
        "binarized_en_indices.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 27, 3519)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeO943vf1a1d"
      },
      "source": [
        "# Creation of tf.data.Dataset for each of the French and English tensors\n",
        "fr_ds = tf.data.Dataset.from_tensor_slices(padded_fr_indices)\n",
        "en_ds = tf.data.Dataset.from_tensor_slices(binarized_en_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZOn0SAFB5eO"
      },
      "source": [
        "# Create a complete tensorflow dataset\n",
        "tf_ds = tf.data.Dataset.zip((fr_ds, en_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qaBwqyjDFbu",
        "outputId": "20248462-cc0e-4999-ab2d-d883c1b20e97"
      },
      "source": [
        "next(iter(tf_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(28,), dtype=int32, numpy=\n",
              " array([2174,  384, 2031, 4493, 2756, 3969, 4389,  453,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(27, 3519), dtype=float32, numpy=\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0aIpW5cZmnh"
      },
      "source": [
        "# Shuffle & Batch\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "tf_ds = tf_ds.shuffle(len(doc)).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCrDIAkMZPUM"
      },
      "source": [
        "# Train Test Split\n",
        "TAKE_SIZE = int(0.7 * len(doc) / BATCH_SIZE)\n",
        "\n",
        "train_data = tf_ds.take(TAKE_SIZE)\n",
        "test_data = tf_ds.skip(TAKE_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NFuUYKHABlD"
      },
      "source": [
        "### Modeling \n",
        "\n",
        "Let's move on to modeling. To create our model, we are going to use: \n",
        "\n",
        "* A layer of [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding?hl=en)\n",
        "* 2 [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM?hl=en) & [Bidirectional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional?hl=en) layers\n",
        "* A [RepeatVector](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RepeatVector?hl=en) layer\n",
        "* A [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?hl=en) & [TimeDistributed](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed?hl=en) output layer\n",
        "\n",
        "The objective being to have in input, a tensor of dimension `(batch_size, max_len_of_french_sentences)` and in output a tensor of dimension `(batch_size, max_len_of_english_sentences, num_of_classes)` where obviously `max_len_of_english_sentences` $\\neq $ `max_len_of_french_sentences`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbbOi7sYVDU2"
      },
      "source": [
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "                  # Input Word Embedding layer        \n",
        "                  tf.keras.layers.Embedding(fr_vocab_size + 1, 64, mask_zero=True),\n",
        "\n",
        "                  # LSTM Bidirectional layer\n",
        "                  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "                  \n",
        "                  # LSTM Bidirectionnal new layer\n",
        "                  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),\n",
        "\n",
        "                  # Repeat Vector\n",
        "                  tf.keras.layers.RepeatVector(binarized_en_indices.shape[1]),\n",
        "\n",
        "                  # LSTM new layer\n",
        "                  tf.keras.layers.LSTM(32, return_sequences=True),               \n",
        "\n",
        "                  # Output layer with number of output neurons equal to class number with softmax function\n",
        "                  tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(en_vocab_size+1, activation=\"softmax\"))\n",
        "           \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVnzzipl6M3m",
        "outputId": "ef359302-1d62-4a69-8336-896972b9c94d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          313856    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 128)         66048     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 27, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 27, 32)            20608     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 27, 3519)          116127    \n",
            "=================================================================\n",
            "Total params: 615,455\n",
            "Trainable params: 615,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqDyYs2LTbSh",
        "outputId": "b0d20945-6028-4448-f7b5-5216614f4182"
      },
      "source": [
        "# \"Random\" prediction to test our model \n",
        "input_text, output_text = next(iter(train_data))\n",
        "print(input_text.numpy().shape)\n",
        "print(model.predict(input_text).shape)\n",
        "print(output_text.numpy().shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 28)\n",
            "(32, 27, 3519)\n",
            "(32, 27, 3519)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj90fL9PZI4c"
      },
      "source": [
        "# Let's create a learning rate schedule to decrease the learning rate as we train the model\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=1090,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "# Using a simple compiler with an Adam optimizer to compute our gradients \n",
        "optimizer= tf.keras.optimizers.Adam(\n",
        "    learning_rate = lr_schedule\n",
        ")\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k5g3sOcY9Iz",
        "outputId": "084baaf1-7895-420e-9821-5baa02a8d0a4"
      },
      "source": [
        "# Application of the model on 200 epochs\n",
        "history = model.fit(train_data,\n",
        "                    validation_data=test_data,\n",
        "                    epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "109/109 [==============================] - 39s 183ms/step - loss: 6.7129 - categorical_accuracy: 0.6887 - val_loss: 2.6877 - val_categorical_accuracy: 0.7226\n",
            "Epoch 2/200\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 2.4216 - categorical_accuracy: 0.7219 - val_loss: 2.1910 - val_categorical_accuracy: 0.7207\n",
            "Epoch 3/200\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 2.1177 - categorical_accuracy: 0.7221 - val_loss: 1.9405 - val_categorical_accuracy: 0.7188\n",
            "Epoch 4/200\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 1.9077 - categorical_accuracy: 0.7201 - val_loss: 1.8168 - val_categorical_accuracy: 0.7216\n",
            "Epoch 5/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.7832 - categorical_accuracy: 0.7236 - val_loss: 1.7402 - val_categorical_accuracy: 0.7230\n",
            "Epoch 6/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 1.7478 - categorical_accuracy: 0.7210 - val_loss: 1.7252 - val_categorical_accuracy: 0.7311\n",
            "Epoch 7/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.7200 - categorical_accuracy: 0.7311 - val_loss: 1.6799 - val_categorical_accuracy: 0.7320\n",
            "Epoch 8/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 1.6581 - categorical_accuracy: 0.7355 - val_loss: 1.6183 - val_categorical_accuracy: 0.7366\n",
            "Epoch 9/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.6353 - categorical_accuracy: 0.7342 - val_loss: 1.6354 - val_categorical_accuracy: 0.7314\n",
            "Epoch 10/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 1.6158 - categorical_accuracy: 0.7353 - val_loss: 1.6159 - val_categorical_accuracy: 0.7343\n",
            "Epoch 11/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.5696 - categorical_accuracy: 0.7423 - val_loss: 1.5338 - val_categorical_accuracy: 0.7551\n",
            "Epoch 12/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.5584 - categorical_accuracy: 0.7469 - val_loss: 1.5298 - val_categorical_accuracy: 0.7480\n",
            "Epoch 13/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.5183 - categorical_accuracy: 0.7557 - val_loss: 1.5201 - val_categorical_accuracy: 0.7545\n",
            "Epoch 14/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.5267 - categorical_accuracy: 0.7536 - val_loss: 1.4965 - val_categorical_accuracy: 0.7589\n",
            "Epoch 15/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.4897 - categorical_accuracy: 0.7592 - val_loss: 1.4824 - val_categorical_accuracy: 0.7526\n",
            "Epoch 16/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4871 - categorical_accuracy: 0.7579 - val_loss: 1.4561 - val_categorical_accuracy: 0.7634\n",
            "Epoch 17/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4899 - categorical_accuracy: 0.7579 - val_loss: 1.4602 - val_categorical_accuracy: 0.7639\n",
            "Epoch 18/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4444 - categorical_accuracy: 0.7643 - val_loss: 1.4521 - val_categorical_accuracy: 0.7636\n",
            "Epoch 19/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4674 - categorical_accuracy: 0.7610 - val_loss: 1.4557 - val_categorical_accuracy: 0.7621\n",
            "Epoch 20/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.4430 - categorical_accuracy: 0.7647 - val_loss: 1.4610 - val_categorical_accuracy: 0.7571\n",
            "Epoch 21/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4550 - categorical_accuracy: 0.7605 - val_loss: 1.4399 - val_categorical_accuracy: 0.7596\n",
            "Epoch 22/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.4556 - categorical_accuracy: 0.7592 - val_loss: 1.4368 - val_categorical_accuracy: 0.7633\n",
            "Epoch 23/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4345 - categorical_accuracy: 0.7627 - val_loss: 1.4120 - val_categorical_accuracy: 0.7689\n",
            "Epoch 24/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4094 - categorical_accuracy: 0.7693 - val_loss: 1.4061 - val_categorical_accuracy: 0.7706\n",
            "Epoch 25/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4216 - categorical_accuracy: 0.7674 - val_loss: 1.3886 - val_categorical_accuracy: 0.7735\n",
            "Epoch 26/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4248 - categorical_accuracy: 0.7671 - val_loss: 1.4107 - val_categorical_accuracy: 0.7685\n",
            "Epoch 27/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.4008 - categorical_accuracy: 0.7704 - val_loss: 1.3971 - val_categorical_accuracy: 0.7708\n",
            "Epoch 28/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.4015 - categorical_accuracy: 0.7701 - val_loss: 1.3834 - val_categorical_accuracy: 0.7703\n",
            "Epoch 29/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.3928 - categorical_accuracy: 0.7709 - val_loss: 1.3787 - val_categorical_accuracy: 0.7727\n",
            "Epoch 30/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.3967 - categorical_accuracy: 0.7674 - val_loss: 1.3775 - val_categorical_accuracy: 0.7728\n",
            "Epoch 31/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.3922 - categorical_accuracy: 0.7694 - val_loss: 1.3969 - val_categorical_accuracy: 0.7698\n",
            "Epoch 32/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.3741 - categorical_accuracy: 0.7726 - val_loss: 1.3903 - val_categorical_accuracy: 0.7693\n",
            "Epoch 33/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.4022 - categorical_accuracy: 0.7651 - val_loss: 1.3887 - val_categorical_accuracy: 0.7663\n",
            "Epoch 34/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.3828 - categorical_accuracy: 0.7698 - val_loss: 1.3657 - val_categorical_accuracy: 0.7722\n",
            "Epoch 35/200\n",
            "109/109 [==============================] - 12s 109ms/step - loss: 1.3749 - categorical_accuracy: 0.7704 - val_loss: 1.3576 - val_categorical_accuracy: 0.7742\n",
            "Epoch 36/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.3536 - categorical_accuracy: 0.7748 - val_loss: 1.3401 - val_categorical_accuracy: 0.7769\n",
            "Epoch 37/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.3323 - categorical_accuracy: 0.7755 - val_loss: 1.3623 - val_categorical_accuracy: 0.7737\n",
            "Epoch 38/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.3324 - categorical_accuracy: 0.7775 - val_loss: 1.3407 - val_categorical_accuracy: 0.7746\n",
            "Epoch 39/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.3334 - categorical_accuracy: 0.7766 - val_loss: 1.3353 - val_categorical_accuracy: 0.7751\n",
            "Epoch 40/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.3284 - categorical_accuracy: 0.7771 - val_loss: 1.3260 - val_categorical_accuracy: 0.7770\n",
            "Epoch 41/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.3041 - categorical_accuracy: 0.7808 - val_loss: 1.2985 - val_categorical_accuracy: 0.7809\n",
            "Epoch 42/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.3118 - categorical_accuracy: 0.7787 - val_loss: 1.2975 - val_categorical_accuracy: 0.7819\n",
            "Epoch 43/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.3081 - categorical_accuracy: 0.7781 - val_loss: 1.3029 - val_categorical_accuracy: 0.7782\n",
            "Epoch 44/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.3032 - categorical_accuracy: 0.7789 - val_loss: 1.2845 - val_categorical_accuracy: 0.7818\n",
            "Epoch 45/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.2894 - categorical_accuracy: 0.7817 - val_loss: 1.2705 - val_categorical_accuracy: 0.7833\n",
            "Epoch 46/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.2927 - categorical_accuracy: 0.7809 - val_loss: 1.2804 - val_categorical_accuracy: 0.7819\n",
            "Epoch 47/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.2675 - categorical_accuracy: 0.7844 - val_loss: 1.2553 - val_categorical_accuracy: 0.7873\n",
            "Epoch 48/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.2756 - categorical_accuracy: 0.7838 - val_loss: 1.2624 - val_categorical_accuracy: 0.7873\n",
            "Epoch 49/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.2585 - categorical_accuracy: 0.7873 - val_loss: 1.2776 - val_categorical_accuracy: 0.7850\n",
            "Epoch 50/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.2703 - categorical_accuracy: 0.7863 - val_loss: 1.2747 - val_categorical_accuracy: 0.7845\n",
            "Epoch 51/200\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 1.2658 - categorical_accuracy: 0.7862 - val_loss: 1.2513 - val_categorical_accuracy: 0.7883\n",
            "Epoch 52/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.2496 - categorical_accuracy: 0.7894 - val_loss: 1.2397 - val_categorical_accuracy: 0.7904\n",
            "Epoch 53/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 1.2606 - categorical_accuracy: 0.7869 - val_loss: 1.2782 - val_categorical_accuracy: 0.7803\n",
            "Epoch 54/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.2317 - categorical_accuracy: 0.7893 - val_loss: 1.2342 - val_categorical_accuracy: 0.7895\n",
            "Epoch 55/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.2515 - categorical_accuracy: 0.7869 - val_loss: 1.2359 - val_categorical_accuracy: 0.7888\n",
            "Epoch 56/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.2458 - categorical_accuracy: 0.7873 - val_loss: 1.2378 - val_categorical_accuracy: 0.7893\n",
            "Epoch 57/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.2212 - categorical_accuracy: 0.7918 - val_loss: 1.2408 - val_categorical_accuracy: 0.7889\n",
            "Epoch 58/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.2218 - categorical_accuracy: 0.7910 - val_loss: 1.2210 - val_categorical_accuracy: 0.7929\n",
            "Epoch 59/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.2116 - categorical_accuracy: 0.7924 - val_loss: 1.1861 - val_categorical_accuracy: 0.7964\n",
            "Epoch 60/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.2124 - categorical_accuracy: 0.7918 - val_loss: 1.2094 - val_categorical_accuracy: 0.7932\n",
            "Epoch 61/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 1.1986 - categorical_accuracy: 0.7943 - val_loss: 1.1819 - val_categorical_accuracy: 0.7971\n",
            "Epoch 62/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.2143 - categorical_accuracy: 0.7902 - val_loss: 1.1754 - val_categorical_accuracy: 0.7980\n",
            "Epoch 63/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1988 - categorical_accuracy: 0.7934 - val_loss: 1.2186 - val_categorical_accuracy: 0.7902\n",
            "Epoch 64/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.2063 - categorical_accuracy: 0.7915 - val_loss: 1.2077 - val_categorical_accuracy: 0.7909\n",
            "Epoch 65/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.1876 - categorical_accuracy: 0.7949 - val_loss: 1.1895 - val_categorical_accuracy: 0.7937\n",
            "Epoch 66/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1665 - categorical_accuracy: 0.7979 - val_loss: 1.1876 - val_categorical_accuracy: 0.7955\n",
            "Epoch 67/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1844 - categorical_accuracy: 0.7955 - val_loss: 1.1682 - val_categorical_accuracy: 0.7974\n",
            "Epoch 68/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.1881 - categorical_accuracy: 0.7939 - val_loss: 1.1653 - val_categorical_accuracy: 0.7961\n",
            "Epoch 69/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.1903 - categorical_accuracy: 0.7936 - val_loss: 1.1765 - val_categorical_accuracy: 0.7939\n",
            "Epoch 70/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.1770 - categorical_accuracy: 0.7953 - val_loss: 1.1618 - val_categorical_accuracy: 0.7968\n",
            "Epoch 71/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.1897 - categorical_accuracy: 0.7928 - val_loss: 1.1559 - val_categorical_accuracy: 0.7980\n",
            "Epoch 72/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1541 - categorical_accuracy: 0.7987 - val_loss: 1.1592 - val_categorical_accuracy: 0.7974\n",
            "Epoch 73/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1578 - categorical_accuracy: 0.7980 - val_loss: 1.1391 - val_categorical_accuracy: 0.8002\n",
            "Epoch 74/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1600 - categorical_accuracy: 0.7974 - val_loss: 1.1398 - val_categorical_accuracy: 0.8000\n",
            "Epoch 75/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1508 - categorical_accuracy: 0.7983 - val_loss: 1.1548 - val_categorical_accuracy: 0.7974\n",
            "Epoch 76/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1485 - categorical_accuracy: 0.7990 - val_loss: 1.1378 - val_categorical_accuracy: 0.7982\n",
            "Epoch 77/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.1497 - categorical_accuracy: 0.7985 - val_loss: 1.1301 - val_categorical_accuracy: 0.8021\n",
            "Epoch 78/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.1365 - categorical_accuracy: 0.8002 - val_loss: 1.1445 - val_categorical_accuracy: 0.7976\n",
            "Epoch 79/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.1358 - categorical_accuracy: 0.7988 - val_loss: 1.1473 - val_categorical_accuracy: 0.7965\n",
            "Epoch 80/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.1495 - categorical_accuracy: 0.7964 - val_loss: 1.1377 - val_categorical_accuracy: 0.7987\n",
            "Epoch 81/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1265 - categorical_accuracy: 0.8006 - val_loss: 1.1358 - val_categorical_accuracy: 0.8000\n",
            "Epoch 82/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1351 - categorical_accuracy: 0.7991 - val_loss: 1.1327 - val_categorical_accuracy: 0.8000\n",
            "Epoch 83/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.1260 - categorical_accuracy: 0.7995 - val_loss: 1.1331 - val_categorical_accuracy: 0.7993\n",
            "Epoch 84/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.1133 - categorical_accuracy: 0.8021 - val_loss: 1.1055 - val_categorical_accuracy: 0.8046\n",
            "Epoch 85/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1059 - categorical_accuracy: 0.8025 - val_loss: 1.1251 - val_categorical_accuracy: 0.8008\n",
            "Epoch 86/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1107 - categorical_accuracy: 0.8027 - val_loss: 1.1038 - val_categorical_accuracy: 0.8044\n",
            "Epoch 87/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1166 - categorical_accuracy: 0.8009 - val_loss: 1.1196 - val_categorical_accuracy: 0.7994\n",
            "Epoch 88/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.1027 - categorical_accuracy: 0.8025 - val_loss: 1.1168 - val_categorical_accuracy: 0.7986\n",
            "Epoch 89/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.1083 - categorical_accuracy: 0.8011 - val_loss: 1.0992 - val_categorical_accuracy: 0.8036\n",
            "Epoch 90/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.1114 - categorical_accuracy: 0.8010 - val_loss: 1.0932 - val_categorical_accuracy: 0.8039\n",
            "Epoch 91/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.1056 - categorical_accuracy: 0.8017 - val_loss: 1.0667 - val_categorical_accuracy: 0.8096\n",
            "Epoch 92/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0951 - categorical_accuracy: 0.8040 - val_loss: 1.1089 - val_categorical_accuracy: 0.7992\n",
            "Epoch 93/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0982 - categorical_accuracy: 0.8023 - val_loss: 1.0855 - val_categorical_accuracy: 0.8047\n",
            "Epoch 94/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0961 - categorical_accuracy: 0.8018 - val_loss: 1.0848 - val_categorical_accuracy: 0.8048\n",
            "Epoch 95/200\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 1.0856 - categorical_accuracy: 0.8041 - val_loss: 1.0839 - val_categorical_accuracy: 0.8042\n",
            "Epoch 96/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0701 - categorical_accuracy: 0.8069 - val_loss: 1.0477 - val_categorical_accuracy: 0.8103\n",
            "Epoch 97/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0851 - categorical_accuracy: 0.8044 - val_loss: 1.0766 - val_categorical_accuracy: 0.8055\n",
            "Epoch 98/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0782 - categorical_accuracy: 0.8048 - val_loss: 1.0642 - val_categorical_accuracy: 0.8068\n",
            "Epoch 99/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0574 - categorical_accuracy: 0.8082 - val_loss: 1.0424 - val_categorical_accuracy: 0.8101\n",
            "Epoch 100/200\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 1.0680 - categorical_accuracy: 0.8060 - val_loss: 1.0650 - val_categorical_accuracy: 0.8072\n",
            "Epoch 101/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0667 - categorical_accuracy: 0.8053 - val_loss: 1.0542 - val_categorical_accuracy: 0.8073\n",
            "Epoch 102/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0491 - categorical_accuracy: 0.8091 - val_loss: 1.0423 - val_categorical_accuracy: 0.8104\n",
            "Epoch 103/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0585 - categorical_accuracy: 0.8063 - val_loss: 1.0650 - val_categorical_accuracy: 0.8050\n",
            "Epoch 104/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0695 - categorical_accuracy: 0.8046 - val_loss: 1.0686 - val_categorical_accuracy: 0.8044\n",
            "Epoch 105/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0582 - categorical_accuracy: 0.8059 - val_loss: 1.0564 - val_categorical_accuracy: 0.8072\n",
            "Epoch 106/200\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 1.0602 - categorical_accuracy: 0.8058 - val_loss: 1.0602 - val_categorical_accuracy: 0.8055\n",
            "Epoch 107/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0600 - categorical_accuracy: 0.8051 - val_loss: 1.0475 - val_categorical_accuracy: 0.8072\n",
            "Epoch 108/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0462 - categorical_accuracy: 0.8075 - val_loss: 1.0577 - val_categorical_accuracy: 0.8050\n",
            "Epoch 109/200\n",
            "109/109 [==============================] - 12s 109ms/step - loss: 1.0414 - categorical_accuracy: 0.8085 - val_loss: 1.0552 - val_categorical_accuracy: 0.8048\n",
            "Epoch 110/200\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 1.0348 - categorical_accuracy: 0.8092 - val_loss: 1.0472 - val_categorical_accuracy: 0.8075\n",
            "Epoch 111/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0305 - categorical_accuracy: 0.8097 - val_loss: 1.0235 - val_categorical_accuracy: 0.8116\n",
            "Epoch 112/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.0272 - categorical_accuracy: 0.8100 - val_loss: 1.0233 - val_categorical_accuracy: 0.8111\n",
            "Epoch 113/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.0173 - categorical_accuracy: 0.8121 - val_loss: 1.0165 - val_categorical_accuracy: 0.8129\n",
            "Epoch 114/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 1.0335 - categorical_accuracy: 0.8088 - val_loss: 1.0061 - val_categorical_accuracy: 0.8126\n",
            "Epoch 115/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.0093 - categorical_accuracy: 0.8132 - val_loss: 1.0047 - val_categorical_accuracy: 0.8136\n",
            "Epoch 116/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0253 - categorical_accuracy: 0.8107 - val_loss: 1.0013 - val_categorical_accuracy: 0.8137\n",
            "Epoch 117/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0371 - categorical_accuracy: 0.8078 - val_loss: 1.0081 - val_categorical_accuracy: 0.8124\n",
            "Epoch 118/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.0224 - categorical_accuracy: 0.8103 - val_loss: 0.9988 - val_categorical_accuracy: 0.8134\n",
            "Epoch 119/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0054 - categorical_accuracy: 0.8130 - val_loss: 1.0241 - val_categorical_accuracy: 0.8090\n",
            "Epoch 120/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0175 - categorical_accuracy: 0.8102 - val_loss: 1.0189 - val_categorical_accuracy: 0.8115\n",
            "Epoch 121/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0118 - categorical_accuracy: 0.8110 - val_loss: 1.0041 - val_categorical_accuracy: 0.8117\n",
            "Epoch 122/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0240 - categorical_accuracy: 0.8094 - val_loss: 1.0136 - val_categorical_accuracy: 0.8117\n",
            "Epoch 123/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 1.0007 - categorical_accuracy: 0.8131 - val_loss: 0.9815 - val_categorical_accuracy: 0.8164\n",
            "Epoch 124/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 1.0170 - categorical_accuracy: 0.8106 - val_loss: 1.0049 - val_categorical_accuracy: 0.8106\n",
            "Epoch 125/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 1.0084 - categorical_accuracy: 0.8120 - val_loss: 1.0161 - val_categorical_accuracy: 0.8095\n",
            "Epoch 126/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9736 - categorical_accuracy: 0.8183 - val_loss: 0.9902 - val_categorical_accuracy: 0.8141\n",
            "Epoch 127/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.9878 - categorical_accuracy: 0.8151 - val_loss: 0.9709 - val_categorical_accuracy: 0.8189\n",
            "Epoch 128/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9970 - categorical_accuracy: 0.8136 - val_loss: 0.9882 - val_categorical_accuracy: 0.8148\n",
            "Epoch 129/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9911 - categorical_accuracy: 0.8147 - val_loss: 0.9796 - val_categorical_accuracy: 0.8155\n",
            "Epoch 130/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 1.0064 - categorical_accuracy: 0.8104 - val_loss: 0.9804 - val_categorical_accuracy: 0.8154\n",
            "Epoch 131/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9766 - categorical_accuracy: 0.8162 - val_loss: 0.9931 - val_categorical_accuracy: 0.8136\n",
            "Epoch 132/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9674 - categorical_accuracy: 0.8184 - val_loss: 0.9829 - val_categorical_accuracy: 0.8151\n",
            "Epoch 133/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9646 - categorical_accuracy: 0.8179 - val_loss: 0.9693 - val_categorical_accuracy: 0.8170\n",
            "Epoch 134/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9737 - categorical_accuracy: 0.8162 - val_loss: 0.9719 - val_categorical_accuracy: 0.8170\n",
            "Epoch 135/200\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.9820 - categorical_accuracy: 0.8157 - val_loss: 0.9809 - val_categorical_accuracy: 0.8148\n",
            "Epoch 136/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9592 - categorical_accuracy: 0.8197 - val_loss: 0.9637 - val_categorical_accuracy: 0.8185\n",
            "Epoch 137/200\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.9709 - categorical_accuracy: 0.8163 - val_loss: 0.9561 - val_categorical_accuracy: 0.8171\n",
            "Epoch 138/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.9717 - categorical_accuracy: 0.8160 - val_loss: 0.9563 - val_categorical_accuracy: 0.8203\n",
            "Epoch 139/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.9655 - categorical_accuracy: 0.8166 - val_loss: 0.9431 - val_categorical_accuracy: 0.8207\n",
            "Epoch 140/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9825 - categorical_accuracy: 0.8146 - val_loss: 0.9602 - val_categorical_accuracy: 0.8180\n",
            "Epoch 141/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9807 - categorical_accuracy: 0.8134 - val_loss: 0.9545 - val_categorical_accuracy: 0.8185\n",
            "Epoch 142/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9486 - categorical_accuracy: 0.8193 - val_loss: 0.9500 - val_categorical_accuracy: 0.8190\n",
            "Epoch 143/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.9437 - categorical_accuracy: 0.8203 - val_loss: 0.9501 - val_categorical_accuracy: 0.8208\n",
            "Epoch 144/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.9585 - categorical_accuracy: 0.8189 - val_loss: 0.9374 - val_categorical_accuracy: 0.8211\n",
            "Epoch 145/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.9509 - categorical_accuracy: 0.8197 - val_loss: 0.9153 - val_categorical_accuracy: 0.8251\n",
            "Epoch 146/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9259 - categorical_accuracy: 0.8226 - val_loss: 0.9344 - val_categorical_accuracy: 0.8224\n",
            "Epoch 147/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9377 - categorical_accuracy: 0.8223 - val_loss: 0.9359 - val_categorical_accuracy: 0.8215\n",
            "Epoch 148/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.9292 - categorical_accuracy: 0.8224 - val_loss: 0.9522 - val_categorical_accuracy: 0.8182\n",
            "Epoch 149/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9593 - categorical_accuracy: 0.8177 - val_loss: 0.9121 - val_categorical_accuracy: 0.8245\n",
            "Epoch 150/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9574 - categorical_accuracy: 0.8163 - val_loss: 0.9277 - val_categorical_accuracy: 0.8231\n",
            "Epoch 151/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9306 - categorical_accuracy: 0.8212 - val_loss: 0.9385 - val_categorical_accuracy: 0.8199\n",
            "Epoch 152/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9195 - categorical_accuracy: 0.8234 - val_loss: 0.9329 - val_categorical_accuracy: 0.8198\n",
            "Epoch 153/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9313 - categorical_accuracy: 0.8225 - val_loss: 0.9329 - val_categorical_accuracy: 0.8215\n",
            "Epoch 154/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9220 - categorical_accuracy: 0.8238 - val_loss: 0.9198 - val_categorical_accuracy: 0.8242\n",
            "Epoch 155/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9201 - categorical_accuracy: 0.8229 - val_loss: 0.9288 - val_categorical_accuracy: 0.8231\n",
            "Epoch 156/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9357 - categorical_accuracy: 0.8208 - val_loss: 0.9279 - val_categorical_accuracy: 0.8227\n",
            "Epoch 157/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9255 - categorical_accuracy: 0.8228 - val_loss: 0.8993 - val_categorical_accuracy: 0.8262\n",
            "Epoch 158/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9290 - categorical_accuracy: 0.8223 - val_loss: 0.9179 - val_categorical_accuracy: 0.8227\n",
            "Epoch 159/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.9041 - categorical_accuracy: 0.8260 - val_loss: 0.9205 - val_categorical_accuracy: 0.8220\n",
            "Epoch 160/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9188 - categorical_accuracy: 0.8232 - val_loss: 0.8984 - val_categorical_accuracy: 0.8260\n",
            "Epoch 161/200\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.9094 - categorical_accuracy: 0.8252 - val_loss: 0.9256 - val_categorical_accuracy: 0.8210\n",
            "Epoch 162/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9043 - categorical_accuracy: 0.8249 - val_loss: 0.8936 - val_categorical_accuracy: 0.8268\n",
            "Epoch 163/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.9162 - categorical_accuracy: 0.8229 - val_loss: 0.9237 - val_categorical_accuracy: 0.8217\n",
            "Epoch 164/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.9005 - categorical_accuracy: 0.8249 - val_loss: 0.9147 - val_categorical_accuracy: 0.8224\n",
            "Epoch 165/200\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.9210 - categorical_accuracy: 0.8223 - val_loss: 0.8935 - val_categorical_accuracy: 0.8261\n",
            "Epoch 166/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9037 - categorical_accuracy: 0.8255 - val_loss: 0.8925 - val_categorical_accuracy: 0.8264\n",
            "Epoch 167/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9153 - categorical_accuracy: 0.8217 - val_loss: 0.8926 - val_categorical_accuracy: 0.8266\n",
            "Epoch 168/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8919 - categorical_accuracy: 0.8261 - val_loss: 0.9049 - val_categorical_accuracy: 0.8237\n",
            "Epoch 169/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.9089 - categorical_accuracy: 0.8234 - val_loss: 0.8929 - val_categorical_accuracy: 0.8263\n",
            "Epoch 170/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.9043 - categorical_accuracy: 0.8233 - val_loss: 0.8847 - val_categorical_accuracy: 0.8279\n",
            "Epoch 171/200\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.8945 - categorical_accuracy: 0.8266 - val_loss: 0.8874 - val_categorical_accuracy: 0.8263\n",
            "Epoch 172/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8843 - categorical_accuracy: 0.8275 - val_loss: 0.8919 - val_categorical_accuracy: 0.8265\n",
            "Epoch 173/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8779 - categorical_accuracy: 0.8290 - val_loss: 0.8806 - val_categorical_accuracy: 0.8281\n",
            "Epoch 174/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8860 - categorical_accuracy: 0.8263 - val_loss: 0.8745 - val_categorical_accuracy: 0.8284\n",
            "Epoch 175/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8909 - categorical_accuracy: 0.8259 - val_loss: 0.8676 - val_categorical_accuracy: 0.8312\n",
            "Epoch 176/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8719 - categorical_accuracy: 0.8299 - val_loss: 0.8734 - val_categorical_accuracy: 0.8295\n",
            "Epoch 177/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8761 - categorical_accuracy: 0.8291 - val_loss: 0.8737 - val_categorical_accuracy: 0.8290\n",
            "Epoch 178/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8809 - categorical_accuracy: 0.8289 - val_loss: 0.8679 - val_categorical_accuracy: 0.8298\n",
            "Epoch 179/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8805 - categorical_accuracy: 0.8263 - val_loss: 0.8566 - val_categorical_accuracy: 0.8330\n",
            "Epoch 180/200\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.8642 - categorical_accuracy: 0.8310 - val_loss: 0.8835 - val_categorical_accuracy: 0.8272\n",
            "Epoch 181/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8687 - categorical_accuracy: 0.8307 - val_loss: 0.8573 - val_categorical_accuracy: 0.8326\n",
            "Epoch 182/200\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.8674 - categorical_accuracy: 0.8318 - val_loss: 0.8470 - val_categorical_accuracy: 0.8333\n",
            "Epoch 183/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8757 - categorical_accuracy: 0.8288 - val_loss: 0.8644 - val_categorical_accuracy: 0.8297\n",
            "Epoch 184/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8758 - categorical_accuracy: 0.8275 - val_loss: 0.8498 - val_categorical_accuracy: 0.8321\n",
            "Epoch 185/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8744 - categorical_accuracy: 0.8285 - val_loss: 0.8622 - val_categorical_accuracy: 0.8296\n",
            "Epoch 186/200\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8689 - categorical_accuracy: 0.8289 - val_loss: 0.8456 - val_categorical_accuracy: 0.8332\n",
            "Epoch 187/200\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.8554 - categorical_accuracy: 0.8314 - val_loss: 0.8459 - val_categorical_accuracy: 0.8328\n",
            "Epoch 188/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8459 - categorical_accuracy: 0.8324 - val_loss: 0.8614 - val_categorical_accuracy: 0.8297\n",
            "Epoch 189/200\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.8604 - categorical_accuracy: 0.8303 - val_loss: 0.8313 - val_categorical_accuracy: 0.8345\n",
            "Epoch 190/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8594 - categorical_accuracy: 0.8302 - val_loss: 0.8462 - val_categorical_accuracy: 0.8335\n",
            "Epoch 191/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8543 - categorical_accuracy: 0.8320 - val_loss: 0.8282 - val_categorical_accuracy: 0.8356\n",
            "Epoch 192/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8622 - categorical_accuracy: 0.8302 - val_loss: 0.8486 - val_categorical_accuracy: 0.8327\n",
            "Epoch 193/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8351 - categorical_accuracy: 0.8341 - val_loss: 0.8574 - val_categorical_accuracy: 0.8306\n",
            "Epoch 194/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8457 - categorical_accuracy: 0.8328 - val_loss: 0.8525 - val_categorical_accuracy: 0.8305\n",
            "Epoch 195/200\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.8505 - categorical_accuracy: 0.8319 - val_loss: 0.8666 - val_categorical_accuracy: 0.8287\n",
            "Epoch 196/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8494 - categorical_accuracy: 0.8310 - val_loss: 0.8462 - val_categorical_accuracy: 0.8327\n",
            "Epoch 197/200\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8333 - categorical_accuracy: 0.8347 - val_loss: 0.8484 - val_categorical_accuracy: 0.8314\n",
            "Epoch 198/200\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.8348 - categorical_accuracy: 0.8338 - val_loss: 0.8377 - val_categorical_accuracy: 0.8343\n",
            "Epoch 199/200\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.8249 - categorical_accuracy: 0.8367 - val_loss: 0.8260 - val_categorical_accuracy: 0.8362\n",
            "Epoch 200/200\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8404 - categorical_accuracy: 0.8333 - val_loss: 0.8429 - val_categorical_accuracy: 0.8312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuQYu8DYZB_L"
      },
      "source": [
        "# Testing a translation\n",
        "for input_text, translation in test_data.take(1):\n",
        "    pred = np.argmax(model.predict(input_text), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4axLz09iPIB"
      },
      "source": [
        "# CAUTION: it's possible because there is only one key for each value\n",
        "indice_to_fr_token = dict(zip(all_fr_tokens.values(), all_fr_tokens.keys()))\n",
        "indice_to_en_token = dict(zip(all_fr_tokens.values(), all_en_tokens.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4hA5S4pAR_K",
        "outputId": "5d49dac8-44c2-4a4b-fbf1-2fc4085657cc"
      },
      "source": [
        "# French Sentence \n",
        "for indice in input_text[0]:\n",
        "    if indice == 0:\n",
        "        break\n",
        "    print(indice_to_fr_token[indice.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tom\n",
            "savait\n",
            "que\n",
            "Mary\n",
            "comprenait\n",
            "ce\n",
            "qu'\n",
            "ils\n",
            "avaient\n",
            "besoin\n",
            "de\n",
            "faire\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3OhO2Hb_qeR",
        "outputId": "74d8bf18-0e76-4d98-b022-c587fd7a6726"
      },
      "source": [
        "# Real English Sentence \n",
        "for indice in np.argmax(translation, axis=-1)[0]:\n",
        "    if indice == 0:\n",
        "        break\n",
        "    print(indice_to_en_token[indice])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tom\n",
            "knew\n",
            "Mary\n",
            "understood\n",
            "what\n",
            "they\n",
            "needed\n",
            "to\n",
            "do\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BssXolD58fn",
        "outputId": "dcf76063-c913-41e5-e5c9-dd4ec09722b7"
      },
      "source": [
        "# Sentence translated into English by the model \n",
        "for indice in pred[0]:\n",
        "    if indice == 0:\n",
        "        break\n",
        "    print(indice_to_en_token[indice])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tom\n",
            "did\n",
            "Mary\n",
            "he\n",
            "what\n",
            "what\n",
            "he\n",
            "to\n",
            "do\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k818RxmJ9A6P",
        "outputId": "9ff591cf-cf8c-469f-9641-7065a1e2b972"
      },
      "source": [
        "# Training on 500 more epochs\n",
        "history_2 = model.fit(train_data,\n",
        "                      validation_data=test_data,\n",
        "                      epochs=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "109/109 [==============================] - 12s 108ms/step - loss: 0.8248 - categorical_accuracy: 0.8354 - val_loss: 0.8245 - val_categorical_accuracy: 0.8351\n",
            "Epoch 2/500\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.8419 - categorical_accuracy: 0.8324 - val_loss: 0.8352 - val_categorical_accuracy: 0.8333\n",
            "Epoch 3/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8330 - categorical_accuracy: 0.8338 - val_loss: 0.8349 - val_categorical_accuracy: 0.8336\n",
            "Epoch 4/500\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.8395 - categorical_accuracy: 0.8327 - val_loss: 0.8368 - val_categorical_accuracy: 0.8326\n",
            "Epoch 5/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8259 - categorical_accuracy: 0.8351 - val_loss: 0.8258 - val_categorical_accuracy: 0.8355\n",
            "Epoch 6/500\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.8354 - categorical_accuracy: 0.8330 - val_loss: 0.8259 - val_categorical_accuracy: 0.8341\n",
            "Epoch 7/500\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.8280 - categorical_accuracy: 0.8345 - val_loss: 0.8329 - val_categorical_accuracy: 0.8329\n",
            "Epoch 8/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8239 - categorical_accuracy: 0.8349 - val_loss: 0.8383 - val_categorical_accuracy: 0.8330\n",
            "Epoch 9/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8293 - categorical_accuracy: 0.8343 - val_loss: 0.8225 - val_categorical_accuracy: 0.8350\n",
            "Epoch 10/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8233 - categorical_accuracy: 0.8354 - val_loss: 0.8150 - val_categorical_accuracy: 0.8365\n",
            "Epoch 11/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8168 - categorical_accuracy: 0.8362 - val_loss: 0.8190 - val_categorical_accuracy: 0.8356\n",
            "Epoch 12/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8207 - categorical_accuracy: 0.8355 - val_loss: 0.8218 - val_categorical_accuracy: 0.8349\n",
            "Epoch 13/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8092 - categorical_accuracy: 0.8378 - val_loss: 0.8314 - val_categorical_accuracy: 0.8333\n",
            "Epoch 14/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.8084 - categorical_accuracy: 0.8380 - val_loss: 0.8141 - val_categorical_accuracy: 0.8364\n",
            "Epoch 15/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8042 - categorical_accuracy: 0.8382 - val_loss: 0.7965 - val_categorical_accuracy: 0.8383\n",
            "Epoch 16/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.8196 - categorical_accuracy: 0.8356 - val_loss: 0.8107 - val_categorical_accuracy: 0.8368\n",
            "Epoch 17/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.8266 - categorical_accuracy: 0.8344 - val_loss: 0.7831 - val_categorical_accuracy: 0.8414\n",
            "Epoch 18/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8135 - categorical_accuracy: 0.8365 - val_loss: 0.8163 - val_categorical_accuracy: 0.8357\n",
            "Epoch 19/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.8114 - categorical_accuracy: 0.8365 - val_loss: 0.8024 - val_categorical_accuracy: 0.8389\n",
            "Epoch 20/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.8091 - categorical_accuracy: 0.8366 - val_loss: 0.7858 - val_categorical_accuracy: 0.8416\n",
            "Epoch 21/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.8059 - categorical_accuracy: 0.8375 - val_loss: 0.7865 - val_categorical_accuracy: 0.8405\n",
            "Epoch 22/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.7999 - categorical_accuracy: 0.8390 - val_loss: 0.8005 - val_categorical_accuracy: 0.8395\n",
            "Epoch 23/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.7997 - categorical_accuracy: 0.8389 - val_loss: 0.7844 - val_categorical_accuracy: 0.8423\n",
            "Epoch 24/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.8028 - categorical_accuracy: 0.8390 - val_loss: 0.7900 - val_categorical_accuracy: 0.8408\n",
            "Epoch 25/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7946 - categorical_accuracy: 0.8397 - val_loss: 0.7829 - val_categorical_accuracy: 0.8427\n",
            "Epoch 26/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7933 - categorical_accuracy: 0.8401 - val_loss: 0.7967 - val_categorical_accuracy: 0.8384\n",
            "Epoch 27/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.8004 - categorical_accuracy: 0.8383 - val_loss: 0.7995 - val_categorical_accuracy: 0.8392\n",
            "Epoch 28/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.8011 - categorical_accuracy: 0.8386 - val_loss: 0.7950 - val_categorical_accuracy: 0.8400\n",
            "Epoch 29/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7915 - categorical_accuracy: 0.8402 - val_loss: 0.7667 - val_categorical_accuracy: 0.8448\n",
            "Epoch 30/500\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.7855 - categorical_accuracy: 0.8412 - val_loss: 0.7775 - val_categorical_accuracy: 0.8426\n",
            "Epoch 31/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7901 - categorical_accuracy: 0.8404 - val_loss: 0.7844 - val_categorical_accuracy: 0.8414\n",
            "Epoch 32/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7936 - categorical_accuracy: 0.8396 - val_loss: 0.7924 - val_categorical_accuracy: 0.8394\n",
            "Epoch 33/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7891 - categorical_accuracy: 0.8401 - val_loss: 0.8011 - val_categorical_accuracy: 0.8379\n",
            "Epoch 34/500\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.7833 - categorical_accuracy: 0.8422 - val_loss: 0.7731 - val_categorical_accuracy: 0.8434\n",
            "Epoch 35/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7868 - categorical_accuracy: 0.8407 - val_loss: 0.7833 - val_categorical_accuracy: 0.8423\n",
            "Epoch 36/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7903 - categorical_accuracy: 0.8395 - val_loss: 0.7921 - val_categorical_accuracy: 0.8392\n",
            "Epoch 37/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7841 - categorical_accuracy: 0.8409 - val_loss: 0.7823 - val_categorical_accuracy: 0.8413\n",
            "Epoch 38/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7826 - categorical_accuracy: 0.8415 - val_loss: 0.7885 - val_categorical_accuracy: 0.8411\n",
            "Epoch 39/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7826 - categorical_accuracy: 0.8416 - val_loss: 0.7886 - val_categorical_accuracy: 0.8415\n",
            "Epoch 40/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7774 - categorical_accuracy: 0.8421 - val_loss: 0.7769 - val_categorical_accuracy: 0.8421\n",
            "Epoch 41/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7684 - categorical_accuracy: 0.8440 - val_loss: 0.7623 - val_categorical_accuracy: 0.8444\n",
            "Epoch 42/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7700 - categorical_accuracy: 0.8441 - val_loss: 0.7596 - val_categorical_accuracy: 0.8456\n",
            "Epoch 43/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7723 - categorical_accuracy: 0.8430 - val_loss: 0.7587 - val_categorical_accuracy: 0.8452\n",
            "Epoch 44/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7727 - categorical_accuracy: 0.8428 - val_loss: 0.7879 - val_categorical_accuracy: 0.8398\n",
            "Epoch 45/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7621 - categorical_accuracy: 0.8455 - val_loss: 0.7784 - val_categorical_accuracy: 0.8421\n",
            "Epoch 46/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7666 - categorical_accuracy: 0.8446 - val_loss: 0.7488 - val_categorical_accuracy: 0.8477\n",
            "Epoch 47/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7667 - categorical_accuracy: 0.8442 - val_loss: 0.7742 - val_categorical_accuracy: 0.8432\n",
            "Epoch 48/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7679 - categorical_accuracy: 0.8437 - val_loss: 0.7691 - val_categorical_accuracy: 0.8450\n",
            "Epoch 49/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7600 - categorical_accuracy: 0.8451 - val_loss: 0.7804 - val_categorical_accuracy: 0.8418\n",
            "Epoch 50/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7623 - categorical_accuracy: 0.8454 - val_loss: 0.7527 - val_categorical_accuracy: 0.8466\n",
            "Epoch 51/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7665 - categorical_accuracy: 0.8442 - val_loss: 0.7671 - val_categorical_accuracy: 0.8453\n",
            "Epoch 52/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.7599 - categorical_accuracy: 0.8456 - val_loss: 0.7421 - val_categorical_accuracy: 0.8479\n",
            "Epoch 53/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7484 - categorical_accuracy: 0.8474 - val_loss: 0.7603 - val_categorical_accuracy: 0.8450\n",
            "Epoch 54/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7497 - categorical_accuracy: 0.8481 - val_loss: 0.7701 - val_categorical_accuracy: 0.8441\n",
            "Epoch 55/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7511 - categorical_accuracy: 0.8468 - val_loss: 0.7532 - val_categorical_accuracy: 0.8456\n",
            "Epoch 56/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7507 - categorical_accuracy: 0.8469 - val_loss: 0.7624 - val_categorical_accuracy: 0.8451\n",
            "Epoch 57/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7554 - categorical_accuracy: 0.8458 - val_loss: 0.7436 - val_categorical_accuracy: 0.8494\n",
            "Epoch 58/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7506 - categorical_accuracy: 0.8467 - val_loss: 0.7535 - val_categorical_accuracy: 0.8475\n",
            "Epoch 59/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7578 - categorical_accuracy: 0.8456 - val_loss: 0.7533 - val_categorical_accuracy: 0.8464\n",
            "Epoch 60/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7497 - categorical_accuracy: 0.8473 - val_loss: 0.7464 - val_categorical_accuracy: 0.8477\n",
            "Epoch 61/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7530 - categorical_accuracy: 0.8466 - val_loss: 0.7490 - val_categorical_accuracy: 0.8471\n",
            "Epoch 62/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7512 - categorical_accuracy: 0.8465 - val_loss: 0.7266 - val_categorical_accuracy: 0.8501\n",
            "Epoch 63/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7446 - categorical_accuracy: 0.8474 - val_loss: 0.7515 - val_categorical_accuracy: 0.8465\n",
            "Epoch 64/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7434 - categorical_accuracy: 0.8489 - val_loss: 0.7260 - val_categorical_accuracy: 0.8507\n",
            "Epoch 65/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7400 - categorical_accuracy: 0.8483 - val_loss: 0.7556 - val_categorical_accuracy: 0.8461\n",
            "Epoch 66/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7366 - categorical_accuracy: 0.8497 - val_loss: 0.7460 - val_categorical_accuracy: 0.8480\n",
            "Epoch 67/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7334 - categorical_accuracy: 0.8505 - val_loss: 0.7361 - val_categorical_accuracy: 0.8501\n",
            "Epoch 68/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7320 - categorical_accuracy: 0.8500 - val_loss: 0.7161 - val_categorical_accuracy: 0.8531\n",
            "Epoch 69/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7417 - categorical_accuracy: 0.8482 - val_loss: 0.7628 - val_categorical_accuracy: 0.8432\n",
            "Epoch 70/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7443 - categorical_accuracy: 0.8483 - val_loss: 0.7277 - val_categorical_accuracy: 0.8517\n",
            "Epoch 71/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.7391 - categorical_accuracy: 0.8498 - val_loss: 0.7406 - val_categorical_accuracy: 0.8478\n",
            "Epoch 72/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7314 - categorical_accuracy: 0.8509 - val_loss: 0.7132 - val_categorical_accuracy: 0.8550\n",
            "Epoch 73/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7337 - categorical_accuracy: 0.8496 - val_loss: 0.7272 - val_categorical_accuracy: 0.8504\n",
            "Epoch 74/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7261 - categorical_accuracy: 0.8510 - val_loss: 0.7284 - val_categorical_accuracy: 0.8507\n",
            "Epoch 75/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7338 - categorical_accuracy: 0.8503 - val_loss: 0.7256 - val_categorical_accuracy: 0.8507\n",
            "Epoch 76/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7270 - categorical_accuracy: 0.8516 - val_loss: 0.7244 - val_categorical_accuracy: 0.8516\n",
            "Epoch 77/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7202 - categorical_accuracy: 0.8524 - val_loss: 0.7120 - val_categorical_accuracy: 0.8533\n",
            "Epoch 78/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7187 - categorical_accuracy: 0.8532 - val_loss: 0.7101 - val_categorical_accuracy: 0.8545\n",
            "Epoch 79/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7177 - categorical_accuracy: 0.8534 - val_loss: 0.7172 - val_categorical_accuracy: 0.8541\n",
            "Epoch 80/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.7215 - categorical_accuracy: 0.8517 - val_loss: 0.7133 - val_categorical_accuracy: 0.8542\n",
            "Epoch 81/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7276 - categorical_accuracy: 0.8514 - val_loss: 0.7190 - val_categorical_accuracy: 0.8522\n",
            "Epoch 82/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7188 - categorical_accuracy: 0.8523 - val_loss: 0.7138 - val_categorical_accuracy: 0.8544\n",
            "Epoch 83/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7297 - categorical_accuracy: 0.8504 - val_loss: 0.7319 - val_categorical_accuracy: 0.8500\n",
            "Epoch 84/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7222 - categorical_accuracy: 0.8518 - val_loss: 0.6981 - val_categorical_accuracy: 0.8561\n",
            "Epoch 85/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.7282 - categorical_accuracy: 0.8507 - val_loss: 0.7423 - val_categorical_accuracy: 0.8489\n",
            "Epoch 86/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7209 - categorical_accuracy: 0.8520 - val_loss: 0.7113 - val_categorical_accuracy: 0.8541\n",
            "Epoch 87/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.7156 - categorical_accuracy: 0.8536 - val_loss: 0.7064 - val_categorical_accuracy: 0.8547\n",
            "Epoch 88/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7153 - categorical_accuracy: 0.8542 - val_loss: 0.7047 - val_categorical_accuracy: 0.8556\n",
            "Epoch 89/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.7124 - categorical_accuracy: 0.8541 - val_loss: 0.7015 - val_categorical_accuracy: 0.8572\n",
            "Epoch 90/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.7123 - categorical_accuracy: 0.8538 - val_loss: 0.6987 - val_categorical_accuracy: 0.8567\n",
            "Epoch 91/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7119 - categorical_accuracy: 0.8537 - val_loss: 0.7149 - val_categorical_accuracy: 0.8523\n",
            "Epoch 92/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7092 - categorical_accuracy: 0.8550 - val_loss: 0.7198 - val_categorical_accuracy: 0.8527\n",
            "Epoch 93/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7075 - categorical_accuracy: 0.8547 - val_loss: 0.7021 - val_categorical_accuracy: 0.8562\n",
            "Epoch 94/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.7076 - categorical_accuracy: 0.8550 - val_loss: 0.6965 - val_categorical_accuracy: 0.8580\n",
            "Epoch 95/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.7080 - categorical_accuracy: 0.8542 - val_loss: 0.7027 - val_categorical_accuracy: 0.8559\n",
            "Epoch 96/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7136 - categorical_accuracy: 0.8544 - val_loss: 0.7199 - val_categorical_accuracy: 0.8521\n",
            "Epoch 97/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.7094 - categorical_accuracy: 0.8551 - val_loss: 0.6877 - val_categorical_accuracy: 0.8594\n",
            "Epoch 98/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6973 - categorical_accuracy: 0.8567 - val_loss: 0.7062 - val_categorical_accuracy: 0.8541\n",
            "Epoch 99/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7121 - categorical_accuracy: 0.8539 - val_loss: 0.7146 - val_categorical_accuracy: 0.8534\n",
            "Epoch 100/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7159 - categorical_accuracy: 0.8536 - val_loss: 0.7311 - val_categorical_accuracy: 0.8512\n",
            "Epoch 101/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.7103 - categorical_accuracy: 0.8543 - val_loss: 0.7043 - val_categorical_accuracy: 0.8552\n",
            "Epoch 102/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.7053 - categorical_accuracy: 0.8549 - val_loss: 0.6866 - val_categorical_accuracy: 0.8589\n",
            "Epoch 103/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6966 - categorical_accuracy: 0.8572 - val_loss: 0.7087 - val_categorical_accuracy: 0.8541\n",
            "Epoch 104/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6946 - categorical_accuracy: 0.8575 - val_loss: 0.6864 - val_categorical_accuracy: 0.8597\n",
            "Epoch 105/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6900 - categorical_accuracy: 0.8582 - val_loss: 0.6916 - val_categorical_accuracy: 0.8580\n",
            "Epoch 106/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6881 - categorical_accuracy: 0.8585 - val_loss: 0.6948 - val_categorical_accuracy: 0.8574\n",
            "Epoch 107/500\n",
            "109/109 [==============================] - 14s 119ms/step - loss: 0.6910 - categorical_accuracy: 0.8580 - val_loss: 0.6988 - val_categorical_accuracy: 0.8578\n",
            "Epoch 108/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6921 - categorical_accuracy: 0.8579 - val_loss: 0.7065 - val_categorical_accuracy: 0.8552\n",
            "Epoch 109/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.7001 - categorical_accuracy: 0.8559 - val_loss: 0.6971 - val_categorical_accuracy: 0.8572\n",
            "Epoch 110/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6933 - categorical_accuracy: 0.8579 - val_loss: 0.7018 - val_categorical_accuracy: 0.8559\n",
            "Epoch 111/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6918 - categorical_accuracy: 0.8579 - val_loss: 0.6918 - val_categorical_accuracy: 0.8598\n",
            "Epoch 112/500\n",
            "109/109 [==============================] - 13s 109ms/step - loss: 0.6931 - categorical_accuracy: 0.8578 - val_loss: 0.6663 - val_categorical_accuracy: 0.8637\n",
            "Epoch 113/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6962 - categorical_accuracy: 0.8567 - val_loss: 0.6974 - val_categorical_accuracy: 0.8564\n",
            "Epoch 114/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6888 - categorical_accuracy: 0.8588 - val_loss: 0.6833 - val_categorical_accuracy: 0.8597\n",
            "Epoch 115/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6860 - categorical_accuracy: 0.8591 - val_loss: 0.7013 - val_categorical_accuracy: 0.8568\n",
            "Epoch 116/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6897 - categorical_accuracy: 0.8579 - val_loss: 0.6661 - val_categorical_accuracy: 0.8645\n",
            "Epoch 117/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6819 - categorical_accuracy: 0.8593 - val_loss: 0.6609 - val_categorical_accuracy: 0.8636\n",
            "Epoch 118/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6798 - categorical_accuracy: 0.8598 - val_loss: 0.6780 - val_categorical_accuracy: 0.8601\n",
            "Epoch 119/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6833 - categorical_accuracy: 0.8590 - val_loss: 0.6754 - val_categorical_accuracy: 0.8621\n",
            "Epoch 120/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6834 - categorical_accuracy: 0.8593 - val_loss: 0.6947 - val_categorical_accuracy: 0.8567\n",
            "Epoch 121/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6987 - categorical_accuracy: 0.8564 - val_loss: 0.6889 - val_categorical_accuracy: 0.8597\n",
            "Epoch 122/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6848 - categorical_accuracy: 0.8594 - val_loss: 0.6779 - val_categorical_accuracy: 0.8603\n",
            "Epoch 123/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6722 - categorical_accuracy: 0.8619 - val_loss: 0.6773 - val_categorical_accuracy: 0.8602\n",
            "Epoch 124/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6783 - categorical_accuracy: 0.8605 - val_loss: 0.6654 - val_categorical_accuracy: 0.8634\n",
            "Epoch 125/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6794 - categorical_accuracy: 0.8600 - val_loss: 0.6708 - val_categorical_accuracy: 0.8626\n",
            "Epoch 126/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6713 - categorical_accuracy: 0.8618 - val_loss: 0.6949 - val_categorical_accuracy: 0.8579\n",
            "Epoch 127/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6714 - categorical_accuracy: 0.8624 - val_loss: 0.6709 - val_categorical_accuracy: 0.8629\n",
            "Epoch 128/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6657 - categorical_accuracy: 0.8638 - val_loss: 0.6575 - val_categorical_accuracy: 0.8648\n",
            "Epoch 129/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6670 - categorical_accuracy: 0.8624 - val_loss: 0.6849 - val_categorical_accuracy: 0.8605\n",
            "Epoch 130/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6744 - categorical_accuracy: 0.8620 - val_loss: 0.6669 - val_categorical_accuracy: 0.8639\n",
            "Epoch 131/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6695 - categorical_accuracy: 0.8619 - val_loss: 0.6552 - val_categorical_accuracy: 0.8649\n",
            "Epoch 132/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6759 - categorical_accuracy: 0.8616 - val_loss: 0.6650 - val_categorical_accuracy: 0.8622\n",
            "Epoch 133/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.6744 - categorical_accuracy: 0.8604 - val_loss: 0.6734 - val_categorical_accuracy: 0.8604\n",
            "Epoch 134/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6833 - categorical_accuracy: 0.8587 - val_loss: 0.6675 - val_categorical_accuracy: 0.8629\n",
            "Epoch 135/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6720 - categorical_accuracy: 0.8613 - val_loss: 0.6740 - val_categorical_accuracy: 0.8605\n",
            "Epoch 136/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6752 - categorical_accuracy: 0.8604 - val_loss: 0.6535 - val_categorical_accuracy: 0.8651\n",
            "Epoch 137/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6613 - categorical_accuracy: 0.8636 - val_loss: 0.6609 - val_categorical_accuracy: 0.8645\n",
            "Epoch 138/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6594 - categorical_accuracy: 0.8639 - val_loss: 0.6571 - val_categorical_accuracy: 0.8649\n",
            "Epoch 139/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6592 - categorical_accuracy: 0.8644 - val_loss: 0.6568 - val_categorical_accuracy: 0.8642\n",
            "Epoch 140/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6624 - categorical_accuracy: 0.8625 - val_loss: 0.6343 - val_categorical_accuracy: 0.8699\n",
            "Epoch 141/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6548 - categorical_accuracy: 0.8659 - val_loss: 0.6525 - val_categorical_accuracy: 0.8658\n",
            "Epoch 142/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6597 - categorical_accuracy: 0.8642 - val_loss: 0.6689 - val_categorical_accuracy: 0.8619\n",
            "Epoch 143/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6554 - categorical_accuracy: 0.8646 - val_loss: 0.6485 - val_categorical_accuracy: 0.8679\n",
            "Epoch 144/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6598 - categorical_accuracy: 0.8639 - val_loss: 0.6531 - val_categorical_accuracy: 0.8654\n",
            "Epoch 145/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.6548 - categorical_accuracy: 0.8654 - val_loss: 0.6585 - val_categorical_accuracy: 0.8648\n",
            "Epoch 146/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6567 - categorical_accuracy: 0.8646 - val_loss: 0.6697 - val_categorical_accuracy: 0.8606\n",
            "Epoch 147/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6611 - categorical_accuracy: 0.8633 - val_loss: 0.6376 - val_categorical_accuracy: 0.8683\n",
            "Epoch 148/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6692 - categorical_accuracy: 0.8618 - val_loss: 0.6774 - val_categorical_accuracy: 0.8598\n",
            "Epoch 149/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6689 - categorical_accuracy: 0.8618 - val_loss: 0.6722 - val_categorical_accuracy: 0.8608\n",
            "Epoch 150/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6573 - categorical_accuracy: 0.8637 - val_loss: 0.6455 - val_categorical_accuracy: 0.8656\n",
            "Epoch 151/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6612 - categorical_accuracy: 0.8642 - val_loss: 0.6558 - val_categorical_accuracy: 0.8641\n",
            "Epoch 152/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6582 - categorical_accuracy: 0.8641 - val_loss: 0.6645 - val_categorical_accuracy: 0.8640\n",
            "Epoch 153/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6529 - categorical_accuracy: 0.8658 - val_loss: 0.6312 - val_categorical_accuracy: 0.8696\n",
            "Epoch 154/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.6506 - categorical_accuracy: 0.8665 - val_loss: 0.6410 - val_categorical_accuracy: 0.8672\n",
            "Epoch 155/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6402 - categorical_accuracy: 0.8685 - val_loss: 0.6487 - val_categorical_accuracy: 0.8669\n",
            "Epoch 156/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6469 - categorical_accuracy: 0.8672 - val_loss: 0.6323 - val_categorical_accuracy: 0.8701\n",
            "Epoch 157/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6529 - categorical_accuracy: 0.8659 - val_loss: 0.6415 - val_categorical_accuracy: 0.8673\n",
            "Epoch 158/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6401 - categorical_accuracy: 0.8683 - val_loss: 0.6316 - val_categorical_accuracy: 0.8700\n",
            "Epoch 159/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6423 - categorical_accuracy: 0.8678 - val_loss: 0.6561 - val_categorical_accuracy: 0.8648\n",
            "Epoch 160/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.6404 - categorical_accuracy: 0.8679 - val_loss: 0.6310 - val_categorical_accuracy: 0.8690\n",
            "Epoch 161/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6450 - categorical_accuracy: 0.8666 - val_loss: 0.6512 - val_categorical_accuracy: 0.8654\n",
            "Epoch 162/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6471 - categorical_accuracy: 0.8666 - val_loss: 0.6272 - val_categorical_accuracy: 0.8708\n",
            "Epoch 163/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6395 - categorical_accuracy: 0.8678 - val_loss: 0.6475 - val_categorical_accuracy: 0.8661\n",
            "Epoch 164/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6430 - categorical_accuracy: 0.8676 - val_loss: 0.6355 - val_categorical_accuracy: 0.8684\n",
            "Epoch 165/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6424 - categorical_accuracy: 0.8674 - val_loss: 0.6449 - val_categorical_accuracy: 0.8669\n",
            "Epoch 166/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6411 - categorical_accuracy: 0.8673 - val_loss: 0.6459 - val_categorical_accuracy: 0.8666\n",
            "Epoch 167/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6433 - categorical_accuracy: 0.8675 - val_loss: 0.6397 - val_categorical_accuracy: 0.8668\n",
            "Epoch 168/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6483 - categorical_accuracy: 0.8663 - val_loss: 0.6492 - val_categorical_accuracy: 0.8662\n",
            "Epoch 169/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6444 - categorical_accuracy: 0.8665 - val_loss: 0.6310 - val_categorical_accuracy: 0.8694\n",
            "Epoch 170/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6404 - categorical_accuracy: 0.8677 - val_loss: 0.6261 - val_categorical_accuracy: 0.8711\n",
            "Epoch 171/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6336 - categorical_accuracy: 0.8688 - val_loss: 0.6270 - val_categorical_accuracy: 0.8710\n",
            "Epoch 172/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6411 - categorical_accuracy: 0.8672 - val_loss: 0.6349 - val_categorical_accuracy: 0.8699\n",
            "Epoch 173/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6420 - categorical_accuracy: 0.8677 - val_loss: 0.6335 - val_categorical_accuracy: 0.8693\n",
            "Epoch 174/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6505 - categorical_accuracy: 0.8652 - val_loss: 0.6551 - val_categorical_accuracy: 0.8651\n",
            "Epoch 175/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6410 - categorical_accuracy: 0.8676 - val_loss: 0.6402 - val_categorical_accuracy: 0.8670\n",
            "Epoch 176/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6336 - categorical_accuracy: 0.8695 - val_loss: 0.6527 - val_categorical_accuracy: 0.8650\n",
            "Epoch 177/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6323 - categorical_accuracy: 0.8687 - val_loss: 0.6407 - val_categorical_accuracy: 0.8681\n",
            "Epoch 178/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6318 - categorical_accuracy: 0.8695 - val_loss: 0.6458 - val_categorical_accuracy: 0.8656\n",
            "Epoch 179/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6219 - categorical_accuracy: 0.8713 - val_loss: 0.6387 - val_categorical_accuracy: 0.8673\n",
            "Epoch 180/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6260 - categorical_accuracy: 0.8706 - val_loss: 0.6388 - val_categorical_accuracy: 0.8681\n",
            "Epoch 181/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6302 - categorical_accuracy: 0.8704 - val_loss: 0.6164 - val_categorical_accuracy: 0.8739\n",
            "Epoch 182/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6299 - categorical_accuracy: 0.8705 - val_loss: 0.6187 - val_categorical_accuracy: 0.8724\n",
            "Epoch 183/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6249 - categorical_accuracy: 0.8707 - val_loss: 0.6360 - val_categorical_accuracy: 0.8685\n",
            "Epoch 184/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6242 - categorical_accuracy: 0.8713 - val_loss: 0.6215 - val_categorical_accuracy: 0.8716\n",
            "Epoch 185/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6339 - categorical_accuracy: 0.8688 - val_loss: 0.6146 - val_categorical_accuracy: 0.8738\n",
            "Epoch 186/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6258 - categorical_accuracy: 0.8706 - val_loss: 0.6269 - val_categorical_accuracy: 0.8705\n",
            "Epoch 187/500\n",
            "109/109 [==============================] - 13s 110ms/step - loss: 0.6298 - categorical_accuracy: 0.8699 - val_loss: 0.6396 - val_categorical_accuracy: 0.8683\n",
            "Epoch 188/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6293 - categorical_accuracy: 0.8698 - val_loss: 0.6347 - val_categorical_accuracy: 0.8688\n",
            "Epoch 189/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6330 - categorical_accuracy: 0.8688 - val_loss: 0.6353 - val_categorical_accuracy: 0.8688\n",
            "Epoch 190/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6268 - categorical_accuracy: 0.8708 - val_loss: 0.6181 - val_categorical_accuracy: 0.8722\n",
            "Epoch 191/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6304 - categorical_accuracy: 0.8693 - val_loss: 0.6242 - val_categorical_accuracy: 0.8714\n",
            "Epoch 192/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6242 - categorical_accuracy: 0.8707 - val_loss: 0.6160 - val_categorical_accuracy: 0.8727\n",
            "Epoch 193/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6287 - categorical_accuracy: 0.8703 - val_loss: 0.6239 - val_categorical_accuracy: 0.8720\n",
            "Epoch 194/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6223 - categorical_accuracy: 0.8714 - val_loss: 0.6118 - val_categorical_accuracy: 0.8738\n",
            "Epoch 195/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6217 - categorical_accuracy: 0.8724 - val_loss: 0.6109 - val_categorical_accuracy: 0.8726\n",
            "Epoch 196/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6126 - categorical_accuracy: 0.8734 - val_loss: 0.6168 - val_categorical_accuracy: 0.8726\n",
            "Epoch 197/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6123 - categorical_accuracy: 0.8730 - val_loss: 0.6244 - val_categorical_accuracy: 0.8710\n",
            "Epoch 198/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6130 - categorical_accuracy: 0.8731 - val_loss: 0.6318 - val_categorical_accuracy: 0.8692\n",
            "Epoch 199/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6068 - categorical_accuracy: 0.8742 - val_loss: 0.6020 - val_categorical_accuracy: 0.8746\n",
            "Epoch 200/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6158 - categorical_accuracy: 0.8727 - val_loss: 0.6005 - val_categorical_accuracy: 0.8764\n",
            "Epoch 201/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6197 - categorical_accuracy: 0.8717 - val_loss: 0.5991 - val_categorical_accuracy: 0.8751\n",
            "Epoch 202/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6119 - categorical_accuracy: 0.8725 - val_loss: 0.6077 - val_categorical_accuracy: 0.8754\n",
            "Epoch 203/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6207 - categorical_accuracy: 0.8712 - val_loss: 0.6370 - val_categorical_accuracy: 0.8680\n",
            "Epoch 204/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6239 - categorical_accuracy: 0.8703 - val_loss: 0.6199 - val_categorical_accuracy: 0.8720\n",
            "Epoch 205/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6221 - categorical_accuracy: 0.8708 - val_loss: 0.6142 - val_categorical_accuracy: 0.8724\n",
            "Epoch 206/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6155 - categorical_accuracy: 0.8725 - val_loss: 0.6239 - val_categorical_accuracy: 0.8700\n",
            "Epoch 207/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6095 - categorical_accuracy: 0.8738 - val_loss: 0.6186 - val_categorical_accuracy: 0.8714\n",
            "Epoch 208/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6118 - categorical_accuracy: 0.8736 - val_loss: 0.6205 - val_categorical_accuracy: 0.8723\n",
            "Epoch 209/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6067 - categorical_accuracy: 0.8744 - val_loss: 0.6043 - val_categorical_accuracy: 0.8751\n",
            "Epoch 210/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6053 - categorical_accuracy: 0.8749 - val_loss: 0.6091 - val_categorical_accuracy: 0.8752\n",
            "Epoch 211/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6017 - categorical_accuracy: 0.8759 - val_loss: 0.6110 - val_categorical_accuracy: 0.8751\n",
            "Epoch 212/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6070 - categorical_accuracy: 0.8747 - val_loss: 0.6062 - val_categorical_accuracy: 0.8735\n",
            "Epoch 213/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6071 - categorical_accuracy: 0.8744 - val_loss: 0.6030 - val_categorical_accuracy: 0.8753\n",
            "Epoch 214/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.6117 - categorical_accuracy: 0.8736 - val_loss: 0.6019 - val_categorical_accuracy: 0.8738\n",
            "Epoch 215/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6110 - categorical_accuracy: 0.8723 - val_loss: 0.6240 - val_categorical_accuracy: 0.8707\n",
            "Epoch 216/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6080 - categorical_accuracy: 0.8742 - val_loss: 0.6095 - val_categorical_accuracy: 0.8738\n",
            "Epoch 217/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6076 - categorical_accuracy: 0.8742 - val_loss: 0.6092 - val_categorical_accuracy: 0.8738\n",
            "Epoch 218/500\n",
            "109/109 [==============================] - 13s 111ms/step - loss: 0.6036 - categorical_accuracy: 0.8744 - val_loss: 0.6038 - val_categorical_accuracy: 0.8746\n",
            "Epoch 219/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6036 - categorical_accuracy: 0.8753 - val_loss: 0.5936 - val_categorical_accuracy: 0.8764\n",
            "Epoch 220/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6054 - categorical_accuracy: 0.8748 - val_loss: 0.6030 - val_categorical_accuracy: 0.8755\n",
            "Epoch 221/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6040 - categorical_accuracy: 0.8751 - val_loss: 0.5922 - val_categorical_accuracy: 0.8782\n",
            "Epoch 222/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5972 - categorical_accuracy: 0.8763 - val_loss: 0.6085 - val_categorical_accuracy: 0.8748\n",
            "Epoch 223/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5982 - categorical_accuracy: 0.8750 - val_loss: 0.6232 - val_categorical_accuracy: 0.8704\n",
            "Epoch 224/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.6104 - categorical_accuracy: 0.8738 - val_loss: 0.5927 - val_categorical_accuracy: 0.8783\n",
            "Epoch 225/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6070 - categorical_accuracy: 0.8742 - val_loss: 0.5919 - val_categorical_accuracy: 0.8773\n",
            "Epoch 226/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.6000 - categorical_accuracy: 0.8751 - val_loss: 0.5931 - val_categorical_accuracy: 0.8772\n",
            "Epoch 227/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.6008 - categorical_accuracy: 0.8754 - val_loss: 0.5829 - val_categorical_accuracy: 0.8794\n",
            "Epoch 228/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5983 - categorical_accuracy: 0.8760 - val_loss: 0.5922 - val_categorical_accuracy: 0.8785\n",
            "Epoch 229/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.6013 - categorical_accuracy: 0.8758 - val_loss: 0.5766 - val_categorical_accuracy: 0.8797\n",
            "Epoch 230/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5899 - categorical_accuracy: 0.8779 - val_loss: 0.5991 - val_categorical_accuracy: 0.8771\n",
            "Epoch 231/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5929 - categorical_accuracy: 0.8773 - val_loss: 0.6050 - val_categorical_accuracy: 0.8763\n",
            "Epoch 232/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5877 - categorical_accuracy: 0.8786 - val_loss: 0.5835 - val_categorical_accuracy: 0.8786\n",
            "Epoch 233/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5869 - categorical_accuracy: 0.8784 - val_loss: 0.6040 - val_categorical_accuracy: 0.8744\n",
            "Epoch 234/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5907 - categorical_accuracy: 0.8779 - val_loss: 0.5926 - val_categorical_accuracy: 0.8786\n",
            "Epoch 235/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5966 - categorical_accuracy: 0.8765 - val_loss: 0.5932 - val_categorical_accuracy: 0.8767\n",
            "Epoch 236/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5959 - categorical_accuracy: 0.8766 - val_loss: 0.5964 - val_categorical_accuracy: 0.8766\n",
            "Epoch 237/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.6067 - categorical_accuracy: 0.8736 - val_loss: 0.5935 - val_categorical_accuracy: 0.8780\n",
            "Epoch 238/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5945 - categorical_accuracy: 0.8770 - val_loss: 0.6194 - val_categorical_accuracy: 0.8724\n",
            "Epoch 239/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5957 - categorical_accuracy: 0.8767 - val_loss: 0.5950 - val_categorical_accuracy: 0.8762\n",
            "Epoch 240/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5923 - categorical_accuracy: 0.8770 - val_loss: 0.5924 - val_categorical_accuracy: 0.8777\n",
            "Epoch 241/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5977 - categorical_accuracy: 0.8765 - val_loss: 0.5895 - val_categorical_accuracy: 0.8773\n",
            "Epoch 242/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5919 - categorical_accuracy: 0.8771 - val_loss: 0.5790 - val_categorical_accuracy: 0.8799\n",
            "Epoch 243/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5942 - categorical_accuracy: 0.8765 - val_loss: 0.5911 - val_categorical_accuracy: 0.8774\n",
            "Epoch 244/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5899 - categorical_accuracy: 0.8776 - val_loss: 0.5864 - val_categorical_accuracy: 0.8786\n",
            "Epoch 245/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.5873 - categorical_accuracy: 0.8785 - val_loss: 0.5836 - val_categorical_accuracy: 0.8788\n",
            "Epoch 246/500\n",
            "109/109 [==============================] - 13s 112ms/step - loss: 0.5844 - categorical_accuracy: 0.8795 - val_loss: 0.5895 - val_categorical_accuracy: 0.8794\n",
            "Epoch 247/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5834 - categorical_accuracy: 0.8793 - val_loss: 0.5950 - val_categorical_accuracy: 0.8765\n",
            "Epoch 248/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5821 - categorical_accuracy: 0.8800 - val_loss: 0.5813 - val_categorical_accuracy: 0.8798\n",
            "Epoch 249/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5883 - categorical_accuracy: 0.8779 - val_loss: 0.5939 - val_categorical_accuracy: 0.8780\n",
            "Epoch 250/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5896 - categorical_accuracy: 0.8776 - val_loss: 0.5768 - val_categorical_accuracy: 0.8805\n",
            "Epoch 251/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5820 - categorical_accuracy: 0.8795 - val_loss: 0.5765 - val_categorical_accuracy: 0.8810\n",
            "Epoch 252/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5877 - categorical_accuracy: 0.8777 - val_loss: 0.6040 - val_categorical_accuracy: 0.8749\n",
            "Epoch 253/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5755 - categorical_accuracy: 0.8806 - val_loss: 0.6015 - val_categorical_accuracy: 0.8742\n",
            "Epoch 254/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5928 - categorical_accuracy: 0.8770 - val_loss: 0.5768 - val_categorical_accuracy: 0.8802\n",
            "Epoch 255/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5846 - categorical_accuracy: 0.8788 - val_loss: 0.5877 - val_categorical_accuracy: 0.8781\n",
            "Epoch 256/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5834 - categorical_accuracy: 0.8780 - val_loss: 0.5678 - val_categorical_accuracy: 0.8821\n",
            "Epoch 257/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5833 - categorical_accuracy: 0.8785 - val_loss: 0.5775 - val_categorical_accuracy: 0.8794\n",
            "Epoch 258/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5806 - categorical_accuracy: 0.8798 - val_loss: 0.5701 - val_categorical_accuracy: 0.8812\n",
            "Epoch 259/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5824 - categorical_accuracy: 0.8796 - val_loss: 0.5805 - val_categorical_accuracy: 0.8791\n",
            "Epoch 260/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5866 - categorical_accuracy: 0.8780 - val_loss: 0.5798 - val_categorical_accuracy: 0.8803\n",
            "Epoch 261/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5798 - categorical_accuracy: 0.8799 - val_loss: 0.5831 - val_categorical_accuracy: 0.8787\n",
            "Epoch 262/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5811 - categorical_accuracy: 0.8799 - val_loss: 0.5916 - val_categorical_accuracy: 0.8770\n",
            "Epoch 263/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5805 - categorical_accuracy: 0.8802 - val_loss: 0.5775 - val_categorical_accuracy: 0.8802\n",
            "Epoch 264/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5775 - categorical_accuracy: 0.8804 - val_loss: 0.5793 - val_categorical_accuracy: 0.8802\n",
            "Epoch 265/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5790 - categorical_accuracy: 0.8798 - val_loss: 0.5797 - val_categorical_accuracy: 0.8794\n",
            "Epoch 266/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5788 - categorical_accuracy: 0.8802 - val_loss: 0.5760 - val_categorical_accuracy: 0.8800\n",
            "Epoch 267/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5827 - categorical_accuracy: 0.8791 - val_loss: 0.5823 - val_categorical_accuracy: 0.8794\n",
            "Epoch 268/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5763 - categorical_accuracy: 0.8800 - val_loss: 0.5573 - val_categorical_accuracy: 0.8850\n",
            "Epoch 269/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5747 - categorical_accuracy: 0.8812 - val_loss: 0.5827 - val_categorical_accuracy: 0.8794\n",
            "Epoch 270/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5717 - categorical_accuracy: 0.8822 - val_loss: 0.5819 - val_categorical_accuracy: 0.8795\n",
            "Epoch 271/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5728 - categorical_accuracy: 0.8817 - val_loss: 0.5730 - val_categorical_accuracy: 0.8811\n",
            "Epoch 272/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5693 - categorical_accuracy: 0.8816 - val_loss: 0.5589 - val_categorical_accuracy: 0.8847\n",
            "Epoch 273/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5695 - categorical_accuracy: 0.8824 - val_loss: 0.5842 - val_categorical_accuracy: 0.8800\n",
            "Epoch 274/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5721 - categorical_accuracy: 0.8815 - val_loss: 0.5827 - val_categorical_accuracy: 0.8789\n",
            "Epoch 275/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5719 - categorical_accuracy: 0.8814 - val_loss: 0.5711 - val_categorical_accuracy: 0.8824\n",
            "Epoch 276/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5728 - categorical_accuracy: 0.8813 - val_loss: 0.5683 - val_categorical_accuracy: 0.8815\n",
            "Epoch 277/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5652 - categorical_accuracy: 0.8827 - val_loss: 0.5721 - val_categorical_accuracy: 0.8807\n",
            "Epoch 278/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5762 - categorical_accuracy: 0.8811 - val_loss: 0.5652 - val_categorical_accuracy: 0.8821\n",
            "Epoch 279/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5703 - categorical_accuracy: 0.8809 - val_loss: 0.5712 - val_categorical_accuracy: 0.8822\n",
            "Epoch 280/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5699 - categorical_accuracy: 0.8818 - val_loss: 0.5645 - val_categorical_accuracy: 0.8822\n",
            "Epoch 281/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5715 - categorical_accuracy: 0.8810 - val_loss: 0.5562 - val_categorical_accuracy: 0.8847\n",
            "Epoch 282/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5794 - categorical_accuracy: 0.8802 - val_loss: 0.5677 - val_categorical_accuracy: 0.8813\n",
            "Epoch 283/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5786 - categorical_accuracy: 0.8798 - val_loss: 0.5759 - val_categorical_accuracy: 0.8807\n",
            "Epoch 284/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5722 - categorical_accuracy: 0.8810 - val_loss: 0.5765 - val_categorical_accuracy: 0.8807\n",
            "Epoch 285/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5668 - categorical_accuracy: 0.8823 - val_loss: 0.5580 - val_categorical_accuracy: 0.8843\n",
            "Epoch 286/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5699 - categorical_accuracy: 0.8815 - val_loss: 0.5695 - val_categorical_accuracy: 0.8818\n",
            "Epoch 287/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5611 - categorical_accuracy: 0.8837 - val_loss: 0.5596 - val_categorical_accuracy: 0.8833\n",
            "Epoch 288/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5765 - categorical_accuracy: 0.8803 - val_loss: 0.5739 - val_categorical_accuracy: 0.8812\n",
            "Epoch 289/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5694 - categorical_accuracy: 0.8821 - val_loss: 0.5766 - val_categorical_accuracy: 0.8807\n",
            "Epoch 290/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5775 - categorical_accuracy: 0.8795 - val_loss: 0.5600 - val_categorical_accuracy: 0.8832\n",
            "Epoch 291/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5739 - categorical_accuracy: 0.8811 - val_loss: 0.5733 - val_categorical_accuracy: 0.8799\n",
            "Epoch 292/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5645 - categorical_accuracy: 0.8829 - val_loss: 0.5638 - val_categorical_accuracy: 0.8829\n",
            "Epoch 293/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5660 - categorical_accuracy: 0.8829 - val_loss: 0.5644 - val_categorical_accuracy: 0.8835\n",
            "Epoch 294/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5661 - categorical_accuracy: 0.8828 - val_loss: 0.5681 - val_categorical_accuracy: 0.8828\n",
            "Epoch 295/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5584 - categorical_accuracy: 0.8843 - val_loss: 0.5545 - val_categorical_accuracy: 0.8848\n",
            "Epoch 296/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5598 - categorical_accuracy: 0.8840 - val_loss: 0.5574 - val_categorical_accuracy: 0.8846\n",
            "Epoch 297/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5617 - categorical_accuracy: 0.8840 - val_loss: 0.5474 - val_categorical_accuracy: 0.8868\n",
            "Epoch 298/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5601 - categorical_accuracy: 0.8846 - val_loss: 0.5667 - val_categorical_accuracy: 0.8832\n",
            "Epoch 299/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5659 - categorical_accuracy: 0.8826 - val_loss: 0.5601 - val_categorical_accuracy: 0.8847\n",
            "Epoch 300/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5616 - categorical_accuracy: 0.8831 - val_loss: 0.5591 - val_categorical_accuracy: 0.8838\n",
            "Epoch 301/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5622 - categorical_accuracy: 0.8830 - val_loss: 0.5551 - val_categorical_accuracy: 0.8856\n",
            "Epoch 302/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5620 - categorical_accuracy: 0.8833 - val_loss: 0.5624 - val_categorical_accuracy: 0.8839\n",
            "Epoch 303/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5681 - categorical_accuracy: 0.8819 - val_loss: 0.5622 - val_categorical_accuracy: 0.8824\n",
            "Epoch 304/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5670 - categorical_accuracy: 0.8823 - val_loss: 0.5673 - val_categorical_accuracy: 0.8822\n",
            "Epoch 305/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5643 - categorical_accuracy: 0.8831 - val_loss: 0.5535 - val_categorical_accuracy: 0.8853\n",
            "Epoch 306/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5628 - categorical_accuracy: 0.8832 - val_loss: 0.5450 - val_categorical_accuracy: 0.8870\n",
            "Epoch 307/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5675 - categorical_accuracy: 0.8818 - val_loss: 0.5503 - val_categorical_accuracy: 0.8848\n",
            "Epoch 308/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5532 - categorical_accuracy: 0.8853 - val_loss: 0.5741 - val_categorical_accuracy: 0.8809\n",
            "Epoch 309/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5567 - categorical_accuracy: 0.8843 - val_loss: 0.5510 - val_categorical_accuracy: 0.8855\n",
            "Epoch 310/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5528 - categorical_accuracy: 0.8855 - val_loss: 0.5428 - val_categorical_accuracy: 0.8883\n",
            "Epoch 311/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5599 - categorical_accuracy: 0.8840 - val_loss: 0.5565 - val_categorical_accuracy: 0.8851\n",
            "Epoch 312/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5459 - categorical_accuracy: 0.8871 - val_loss: 0.5551 - val_categorical_accuracy: 0.8832\n",
            "Epoch 313/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5504 - categorical_accuracy: 0.8862 - val_loss: 0.5585 - val_categorical_accuracy: 0.8835\n",
            "Epoch 314/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5442 - categorical_accuracy: 0.8867 - val_loss: 0.5602 - val_categorical_accuracy: 0.8842\n",
            "Epoch 315/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5649 - categorical_accuracy: 0.8826 - val_loss: 0.5685 - val_categorical_accuracy: 0.8805\n",
            "Epoch 316/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5580 - categorical_accuracy: 0.8836 - val_loss: 0.5405 - val_categorical_accuracy: 0.8887\n",
            "Epoch 317/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5506 - categorical_accuracy: 0.8859 - val_loss: 0.5432 - val_categorical_accuracy: 0.8882\n",
            "Epoch 318/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5523 - categorical_accuracy: 0.8851 - val_loss: 0.5333 - val_categorical_accuracy: 0.8880\n",
            "Epoch 319/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5500 - categorical_accuracy: 0.8855 - val_loss: 0.5705 - val_categorical_accuracy: 0.8812\n",
            "Epoch 320/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5509 - categorical_accuracy: 0.8856 - val_loss: 0.5565 - val_categorical_accuracy: 0.8826\n",
            "Epoch 321/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5535 - categorical_accuracy: 0.8848 - val_loss: 0.5476 - val_categorical_accuracy: 0.8866\n",
            "Epoch 322/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5547 - categorical_accuracy: 0.8848 - val_loss: 0.5399 - val_categorical_accuracy: 0.8885\n",
            "Epoch 323/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5501 - categorical_accuracy: 0.8861 - val_loss: 0.5441 - val_categorical_accuracy: 0.8877\n",
            "Epoch 324/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5531 - categorical_accuracy: 0.8853 - val_loss: 0.5571 - val_categorical_accuracy: 0.8848\n",
            "Epoch 325/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5485 - categorical_accuracy: 0.8862 - val_loss: 0.5672 - val_categorical_accuracy: 0.8822\n",
            "Epoch 326/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5543 - categorical_accuracy: 0.8853 - val_loss: 0.5508 - val_categorical_accuracy: 0.8857\n",
            "Epoch 327/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5502 - categorical_accuracy: 0.8860 - val_loss: 0.5472 - val_categorical_accuracy: 0.8870\n",
            "Epoch 328/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5415 - categorical_accuracy: 0.8875 - val_loss: 0.5480 - val_categorical_accuracy: 0.8864\n",
            "Epoch 329/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5429 - categorical_accuracy: 0.8872 - val_loss: 0.5463 - val_categorical_accuracy: 0.8868\n",
            "Epoch 330/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5489 - categorical_accuracy: 0.8864 - val_loss: 0.5463 - val_categorical_accuracy: 0.8859\n",
            "Epoch 331/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5485 - categorical_accuracy: 0.8859 - val_loss: 0.5532 - val_categorical_accuracy: 0.8851\n",
            "Epoch 332/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5516 - categorical_accuracy: 0.8852 - val_loss: 0.5411 - val_categorical_accuracy: 0.8897\n",
            "Epoch 333/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5541 - categorical_accuracy: 0.8850 - val_loss: 0.5507 - val_categorical_accuracy: 0.8856\n",
            "Epoch 334/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5429 - categorical_accuracy: 0.8879 - val_loss: 0.5509 - val_categorical_accuracy: 0.8865\n",
            "Epoch 335/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5495 - categorical_accuracy: 0.8856 - val_loss: 0.5342 - val_categorical_accuracy: 0.8899\n",
            "Epoch 336/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5421 - categorical_accuracy: 0.8876 - val_loss: 0.5484 - val_categorical_accuracy: 0.8856\n",
            "Epoch 337/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5520 - categorical_accuracy: 0.8855 - val_loss: 0.5361 - val_categorical_accuracy: 0.8874\n",
            "Epoch 338/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5412 - categorical_accuracy: 0.8878 - val_loss: 0.5425 - val_categorical_accuracy: 0.8883\n",
            "Epoch 339/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5448 - categorical_accuracy: 0.8870 - val_loss: 0.5622 - val_categorical_accuracy: 0.8836\n",
            "Epoch 340/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5405 - categorical_accuracy: 0.8877 - val_loss: 0.5413 - val_categorical_accuracy: 0.8875\n",
            "Epoch 341/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5448 - categorical_accuracy: 0.8867 - val_loss: 0.5536 - val_categorical_accuracy: 0.8850\n",
            "Epoch 342/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5462 - categorical_accuracy: 0.8863 - val_loss: 0.5396 - val_categorical_accuracy: 0.8890\n",
            "Epoch 343/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5558 - categorical_accuracy: 0.8845 - val_loss: 0.5301 - val_categorical_accuracy: 0.8895\n",
            "Epoch 344/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5473 - categorical_accuracy: 0.8866 - val_loss: 0.5425 - val_categorical_accuracy: 0.8881\n",
            "Epoch 345/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5436 - categorical_accuracy: 0.8872 - val_loss: 0.5549 - val_categorical_accuracy: 0.8846\n",
            "Epoch 346/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5392 - categorical_accuracy: 0.8878 - val_loss: 0.5359 - val_categorical_accuracy: 0.8887\n",
            "Epoch 347/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5439 - categorical_accuracy: 0.8872 - val_loss: 0.5455 - val_categorical_accuracy: 0.8863\n",
            "Epoch 348/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5429 - categorical_accuracy: 0.8871 - val_loss: 0.5457 - val_categorical_accuracy: 0.8882\n",
            "Epoch 349/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5441 - categorical_accuracy: 0.8875 - val_loss: 0.5305 - val_categorical_accuracy: 0.8889\n",
            "Epoch 350/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5512 - categorical_accuracy: 0.8854 - val_loss: 0.5512 - val_categorical_accuracy: 0.8847\n",
            "Epoch 351/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5407 - categorical_accuracy: 0.8879 - val_loss: 0.5539 - val_categorical_accuracy: 0.8839\n",
            "Epoch 352/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5442 - categorical_accuracy: 0.8872 - val_loss: 0.5460 - val_categorical_accuracy: 0.8868\n",
            "Epoch 353/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5370 - categorical_accuracy: 0.8890 - val_loss: 0.5374 - val_categorical_accuracy: 0.8889\n",
            "Epoch 354/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5464 - categorical_accuracy: 0.8868 - val_loss: 0.5372 - val_categorical_accuracy: 0.8881\n",
            "Epoch 355/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5417 - categorical_accuracy: 0.8876 - val_loss: 0.5343 - val_categorical_accuracy: 0.8885\n",
            "Epoch 356/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5382 - categorical_accuracy: 0.8884 - val_loss: 0.5352 - val_categorical_accuracy: 0.8893\n",
            "Epoch 357/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5360 - categorical_accuracy: 0.8887 - val_loss: 0.5315 - val_categorical_accuracy: 0.8895\n",
            "Epoch 358/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5428 - categorical_accuracy: 0.8873 - val_loss: 0.5461 - val_categorical_accuracy: 0.8871\n",
            "Epoch 359/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5456 - categorical_accuracy: 0.8863 - val_loss: 0.5534 - val_categorical_accuracy: 0.8853\n",
            "Epoch 360/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5343 - categorical_accuracy: 0.8891 - val_loss: 0.5248 - val_categorical_accuracy: 0.8916\n",
            "Epoch 361/500\n",
            "109/109 [==============================] - 14s 119ms/step - loss: 0.5397 - categorical_accuracy: 0.8875 - val_loss: 0.5374 - val_categorical_accuracy: 0.8886\n",
            "Epoch 362/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5343 - categorical_accuracy: 0.8890 - val_loss: 0.5270 - val_categorical_accuracy: 0.8910\n",
            "Epoch 363/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5365 - categorical_accuracy: 0.8885 - val_loss: 0.5370 - val_categorical_accuracy: 0.8878\n",
            "Epoch 364/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5405 - categorical_accuracy: 0.8872 - val_loss: 0.5283 - val_categorical_accuracy: 0.8909\n",
            "Epoch 365/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5348 - categorical_accuracy: 0.8888 - val_loss: 0.5429 - val_categorical_accuracy: 0.8876\n",
            "Epoch 366/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5352 - categorical_accuracy: 0.8891 - val_loss: 0.5233 - val_categorical_accuracy: 0.8924\n",
            "Epoch 367/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5327 - categorical_accuracy: 0.8892 - val_loss: 0.5198 - val_categorical_accuracy: 0.8916\n",
            "Epoch 368/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5322 - categorical_accuracy: 0.8893 - val_loss: 0.5401 - val_categorical_accuracy: 0.8892\n",
            "Epoch 369/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5415 - categorical_accuracy: 0.8878 - val_loss: 0.5503 - val_categorical_accuracy: 0.8854\n",
            "Epoch 370/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5442 - categorical_accuracy: 0.8868 - val_loss: 0.5269 - val_categorical_accuracy: 0.8899\n",
            "Epoch 371/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5303 - categorical_accuracy: 0.8900 - val_loss: 0.5294 - val_categorical_accuracy: 0.8890\n",
            "Epoch 372/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5412 - categorical_accuracy: 0.8879 - val_loss: 0.5255 - val_categorical_accuracy: 0.8912\n",
            "Epoch 373/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5413 - categorical_accuracy: 0.8881 - val_loss: 0.5306 - val_categorical_accuracy: 0.8899\n",
            "Epoch 374/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5284 - categorical_accuracy: 0.8904 - val_loss: 0.5318 - val_categorical_accuracy: 0.8900\n",
            "Epoch 375/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5242 - categorical_accuracy: 0.8910 - val_loss: 0.5424 - val_categorical_accuracy: 0.8873\n",
            "Epoch 376/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5389 - categorical_accuracy: 0.8885 - val_loss: 0.5343 - val_categorical_accuracy: 0.8893\n",
            "Epoch 377/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5372 - categorical_accuracy: 0.8885 - val_loss: 0.5271 - val_categorical_accuracy: 0.8898\n",
            "Epoch 378/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5304 - categorical_accuracy: 0.8900 - val_loss: 0.5181 - val_categorical_accuracy: 0.8929\n",
            "Epoch 379/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5291 - categorical_accuracy: 0.8904 - val_loss: 0.5199 - val_categorical_accuracy: 0.8921\n",
            "Epoch 380/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5293 - categorical_accuracy: 0.8901 - val_loss: 0.5191 - val_categorical_accuracy: 0.8933\n",
            "Epoch 381/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5273 - categorical_accuracy: 0.8905 - val_loss: 0.5338 - val_categorical_accuracy: 0.8898\n",
            "Epoch 382/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5272 - categorical_accuracy: 0.8905 - val_loss: 0.5332 - val_categorical_accuracy: 0.8901\n",
            "Epoch 383/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5259 - categorical_accuracy: 0.8905 - val_loss: 0.5388 - val_categorical_accuracy: 0.8886\n",
            "Epoch 384/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5399 - categorical_accuracy: 0.8876 - val_loss: 0.5298 - val_categorical_accuracy: 0.8903\n",
            "Epoch 385/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5388 - categorical_accuracy: 0.8885 - val_loss: 0.5320 - val_categorical_accuracy: 0.8879\n",
            "Epoch 386/500\n",
            "109/109 [==============================] - 13s 118ms/step - loss: 0.5353 - categorical_accuracy: 0.8881 - val_loss: 0.5290 - val_categorical_accuracy: 0.8904\n",
            "Epoch 387/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5270 - categorical_accuracy: 0.8905 - val_loss: 0.5374 - val_categorical_accuracy: 0.8879\n",
            "Epoch 388/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5313 - categorical_accuracy: 0.8889 - val_loss: 0.5262 - val_categorical_accuracy: 0.8915\n",
            "Epoch 389/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5302 - categorical_accuracy: 0.8898 - val_loss: 0.5308 - val_categorical_accuracy: 0.8901\n",
            "Epoch 390/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5258 - categorical_accuracy: 0.8909 - val_loss: 0.5332 - val_categorical_accuracy: 0.8889\n",
            "Epoch 391/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5289 - categorical_accuracy: 0.8904 - val_loss: 0.5237 - val_categorical_accuracy: 0.8913\n",
            "Epoch 392/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5195 - categorical_accuracy: 0.8931 - val_loss: 0.5219 - val_categorical_accuracy: 0.8925\n",
            "Epoch 393/500\n",
            "109/109 [==============================] - 13s 118ms/step - loss: 0.5272 - categorical_accuracy: 0.8906 - val_loss: 0.5231 - val_categorical_accuracy: 0.8918\n",
            "Epoch 394/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5279 - categorical_accuracy: 0.8902 - val_loss: 0.5127 - val_categorical_accuracy: 0.8931\n",
            "Epoch 395/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5276 - categorical_accuracy: 0.8909 - val_loss: 0.5265 - val_categorical_accuracy: 0.8905\n",
            "Epoch 396/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5329 - categorical_accuracy: 0.8889 - val_loss: 0.5167 - val_categorical_accuracy: 0.8934\n",
            "Epoch 397/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5340 - categorical_accuracy: 0.8892 - val_loss: 0.5147 - val_categorical_accuracy: 0.8934\n",
            "Epoch 398/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5340 - categorical_accuracy: 0.8896 - val_loss: 0.5428 - val_categorical_accuracy: 0.8871\n",
            "Epoch 399/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5297 - categorical_accuracy: 0.8896 - val_loss: 0.5357 - val_categorical_accuracy: 0.8885\n",
            "Epoch 400/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5387 - categorical_accuracy: 0.8881 - val_loss: 0.5323 - val_categorical_accuracy: 0.8890\n",
            "Epoch 401/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5269 - categorical_accuracy: 0.8905 - val_loss: 0.5275 - val_categorical_accuracy: 0.8892\n",
            "Epoch 402/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5301 - categorical_accuracy: 0.8899 - val_loss: 0.5353 - val_categorical_accuracy: 0.8896\n",
            "Epoch 403/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5249 - categorical_accuracy: 0.8915 - val_loss: 0.5158 - val_categorical_accuracy: 0.8940\n",
            "Epoch 404/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5151 - categorical_accuracy: 0.8926 - val_loss: 0.5293 - val_categorical_accuracy: 0.8899\n",
            "Epoch 405/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5245 - categorical_accuracy: 0.8911 - val_loss: 0.5115 - val_categorical_accuracy: 0.8949\n",
            "Epoch 406/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5237 - categorical_accuracy: 0.8914 - val_loss: 0.5307 - val_categorical_accuracy: 0.8900\n",
            "Epoch 407/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5212 - categorical_accuracy: 0.8915 - val_loss: 0.5212 - val_categorical_accuracy: 0.8922\n",
            "Epoch 408/500\n",
            "109/109 [==============================] - 13s 118ms/step - loss: 0.5183 - categorical_accuracy: 0.8926 - val_loss: 0.5181 - val_categorical_accuracy: 0.8926\n",
            "Epoch 409/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5301 - categorical_accuracy: 0.8903 - val_loss: 0.5091 - val_categorical_accuracy: 0.8953\n",
            "Epoch 410/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5196 - categorical_accuracy: 0.8924 - val_loss: 0.5313 - val_categorical_accuracy: 0.8909\n",
            "Epoch 411/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5183 - categorical_accuracy: 0.8926 - val_loss: 0.5057 - val_categorical_accuracy: 0.8952\n",
            "Epoch 412/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5298 - categorical_accuracy: 0.8902 - val_loss: 0.5209 - val_categorical_accuracy: 0.8910\n",
            "Epoch 413/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5213 - categorical_accuracy: 0.8912 - val_loss: 0.5137 - val_categorical_accuracy: 0.8929\n",
            "Epoch 414/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5213 - categorical_accuracy: 0.8916 - val_loss: 0.5082 - val_categorical_accuracy: 0.8952\n",
            "Epoch 415/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5237 - categorical_accuracy: 0.8919 - val_loss: 0.5271 - val_categorical_accuracy: 0.8909\n",
            "Epoch 416/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5154 - categorical_accuracy: 0.8932 - val_loss: 0.5182 - val_categorical_accuracy: 0.8929\n",
            "Epoch 417/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5212 - categorical_accuracy: 0.8921 - val_loss: 0.5390 - val_categorical_accuracy: 0.8888\n",
            "Epoch 418/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5205 - categorical_accuracy: 0.8917 - val_loss: 0.5195 - val_categorical_accuracy: 0.8924\n",
            "Epoch 419/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5225 - categorical_accuracy: 0.8920 - val_loss: 0.5274 - val_categorical_accuracy: 0.8917\n",
            "Epoch 420/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5238 - categorical_accuracy: 0.8909 - val_loss: 0.4928 - val_categorical_accuracy: 0.8978\n",
            "Epoch 421/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5214 - categorical_accuracy: 0.8922 - val_loss: 0.5143 - val_categorical_accuracy: 0.8940\n",
            "Epoch 422/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5192 - categorical_accuracy: 0.8921 - val_loss: 0.5212 - val_categorical_accuracy: 0.8929\n",
            "Epoch 423/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5204 - categorical_accuracy: 0.8923 - val_loss: 0.5131 - val_categorical_accuracy: 0.8946\n",
            "Epoch 424/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5155 - categorical_accuracy: 0.8934 - val_loss: 0.5136 - val_categorical_accuracy: 0.8935\n",
            "Epoch 425/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5157 - categorical_accuracy: 0.8933 - val_loss: 0.5303 - val_categorical_accuracy: 0.8901\n",
            "Epoch 426/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5171 - categorical_accuracy: 0.8929 - val_loss: 0.5094 - val_categorical_accuracy: 0.8943\n",
            "Epoch 427/500\n",
            "109/109 [==============================] - 14s 119ms/step - loss: 0.5219 - categorical_accuracy: 0.8915 - val_loss: 0.5211 - val_categorical_accuracy: 0.8902\n",
            "Epoch 428/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5224 - categorical_accuracy: 0.8920 - val_loss: 0.5197 - val_categorical_accuracy: 0.8919\n",
            "Epoch 429/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5140 - categorical_accuracy: 0.8938 - val_loss: 0.5173 - val_categorical_accuracy: 0.8926\n",
            "Epoch 430/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5152 - categorical_accuracy: 0.8927 - val_loss: 0.4992 - val_categorical_accuracy: 0.8968\n",
            "Epoch 431/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5207 - categorical_accuracy: 0.8926 - val_loss: 0.5127 - val_categorical_accuracy: 0.8936\n",
            "Epoch 432/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5176 - categorical_accuracy: 0.8926 - val_loss: 0.5136 - val_categorical_accuracy: 0.8938\n",
            "Epoch 433/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5180 - categorical_accuracy: 0.8928 - val_loss: 0.5148 - val_categorical_accuracy: 0.8931\n",
            "Epoch 434/500\n",
            "109/109 [==============================] - 13s 118ms/step - loss: 0.5133 - categorical_accuracy: 0.8937 - val_loss: 0.5236 - val_categorical_accuracy: 0.8911\n",
            "Epoch 435/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5112 - categorical_accuracy: 0.8944 - val_loss: 0.5075 - val_categorical_accuracy: 0.8945\n",
            "Epoch 436/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5224 - categorical_accuracy: 0.8912 - val_loss: 0.5196 - val_categorical_accuracy: 0.8906\n",
            "Epoch 437/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5204 - categorical_accuracy: 0.8922 - val_loss: 0.5200 - val_categorical_accuracy: 0.8919\n",
            "Epoch 438/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5111 - categorical_accuracy: 0.8939 - val_loss: 0.5129 - val_categorical_accuracy: 0.8948\n",
            "Epoch 439/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5172 - categorical_accuracy: 0.8927 - val_loss: 0.5031 - val_categorical_accuracy: 0.8960\n",
            "Epoch 440/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5140 - categorical_accuracy: 0.8931 - val_loss: 0.5176 - val_categorical_accuracy: 0.8930\n",
            "Epoch 441/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5092 - categorical_accuracy: 0.8942 - val_loss: 0.5142 - val_categorical_accuracy: 0.8939\n",
            "Epoch 442/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5189 - categorical_accuracy: 0.8924 - val_loss: 0.5068 - val_categorical_accuracy: 0.8952\n",
            "Epoch 443/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5202 - categorical_accuracy: 0.8917 - val_loss: 0.5223 - val_categorical_accuracy: 0.8924\n",
            "Epoch 444/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5176 - categorical_accuracy: 0.8925 - val_loss: 0.5019 - val_categorical_accuracy: 0.8955\n",
            "Epoch 445/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5127 - categorical_accuracy: 0.8940 - val_loss: 0.5276 - val_categorical_accuracy: 0.8887\n",
            "Epoch 446/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5094 - categorical_accuracy: 0.8944 - val_loss: 0.5133 - val_categorical_accuracy: 0.8928\n",
            "Epoch 447/500\n",
            "109/109 [==============================] - 13s 113ms/step - loss: 0.5142 - categorical_accuracy: 0.8930 - val_loss: 0.5159 - val_categorical_accuracy: 0.8932\n",
            "Epoch 448/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5113 - categorical_accuracy: 0.8937 - val_loss: 0.5132 - val_categorical_accuracy: 0.8942\n",
            "Epoch 449/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5108 - categorical_accuracy: 0.8943 - val_loss: 0.5047 - val_categorical_accuracy: 0.8958\n",
            "Epoch 450/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5032 - categorical_accuracy: 0.8955 - val_loss: 0.5082 - val_categorical_accuracy: 0.8948\n",
            "Epoch 451/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5072 - categorical_accuracy: 0.8947 - val_loss: 0.5107 - val_categorical_accuracy: 0.8949\n",
            "Epoch 452/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5090 - categorical_accuracy: 0.8944 - val_loss: 0.5322 - val_categorical_accuracy: 0.8890\n",
            "Epoch 453/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5138 - categorical_accuracy: 0.8933 - val_loss: 0.5043 - val_categorical_accuracy: 0.8947\n",
            "Epoch 454/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5085 - categorical_accuracy: 0.8947 - val_loss: 0.5189 - val_categorical_accuracy: 0.8933\n",
            "Epoch 455/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5103 - categorical_accuracy: 0.8938 - val_loss: 0.5161 - val_categorical_accuracy: 0.8927\n",
            "Epoch 456/500\n",
            "109/109 [==============================] - 13s 118ms/step - loss: 0.5092 - categorical_accuracy: 0.8948 - val_loss: 0.5335 - val_categorical_accuracy: 0.8893\n",
            "Epoch 457/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5121 - categorical_accuracy: 0.8939 - val_loss: 0.5179 - val_categorical_accuracy: 0.8923\n",
            "Epoch 458/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5098 - categorical_accuracy: 0.8941 - val_loss: 0.5035 - val_categorical_accuracy: 0.8956\n",
            "Epoch 459/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5180 - categorical_accuracy: 0.8920 - val_loss: 0.5019 - val_categorical_accuracy: 0.8963\n",
            "Epoch 460/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5111 - categorical_accuracy: 0.8936 - val_loss: 0.5152 - val_categorical_accuracy: 0.8916\n",
            "Epoch 461/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5111 - categorical_accuracy: 0.8941 - val_loss: 0.5068 - val_categorical_accuracy: 0.8950\n",
            "Epoch 462/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5052 - categorical_accuracy: 0.8961 - val_loss: 0.5033 - val_categorical_accuracy: 0.8945\n",
            "Epoch 463/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5053 - categorical_accuracy: 0.8957 - val_loss: 0.4920 - val_categorical_accuracy: 0.8980\n",
            "Epoch 464/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5048 - categorical_accuracy: 0.8956 - val_loss: 0.5123 - val_categorical_accuracy: 0.8931\n",
            "Epoch 465/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5074 - categorical_accuracy: 0.8951 - val_loss: 0.5096 - val_categorical_accuracy: 0.8945\n",
            "Epoch 466/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5060 - categorical_accuracy: 0.8954 - val_loss: 0.5253 - val_categorical_accuracy: 0.8914\n",
            "Epoch 467/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5053 - categorical_accuracy: 0.8951 - val_loss: 0.5182 - val_categorical_accuracy: 0.8938\n",
            "Epoch 468/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5073 - categorical_accuracy: 0.8951 - val_loss: 0.5137 - val_categorical_accuracy: 0.8931\n",
            "Epoch 469/500\n",
            "109/109 [==============================] - 13s 118ms/step - loss: 0.5112 - categorical_accuracy: 0.8936 - val_loss: 0.4977 - val_categorical_accuracy: 0.8978\n",
            "Epoch 470/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.4989 - categorical_accuracy: 0.8968 - val_loss: 0.5064 - val_categorical_accuracy: 0.8954\n",
            "Epoch 471/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5085 - categorical_accuracy: 0.8949 - val_loss: 0.4951 - val_categorical_accuracy: 0.8967\n",
            "Epoch 472/500\n",
            "109/109 [==============================] - 14s 120ms/step - loss: 0.5053 - categorical_accuracy: 0.8949 - val_loss: 0.5065 - val_categorical_accuracy: 0.8956\n",
            "Epoch 473/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5050 - categorical_accuracy: 0.8951 - val_loss: 0.5179 - val_categorical_accuracy: 0.8922\n",
            "Epoch 474/500\n",
            "109/109 [==============================] - 14s 120ms/step - loss: 0.5145 - categorical_accuracy: 0.8934 - val_loss: 0.5021 - val_categorical_accuracy: 0.8961\n",
            "Epoch 475/500\n",
            "109/109 [==============================] - 14s 120ms/step - loss: 0.5105 - categorical_accuracy: 0.8942 - val_loss: 0.5017 - val_categorical_accuracy: 0.8960\n",
            "Epoch 476/500\n",
            "109/109 [==============================] - 14s 119ms/step - loss: 0.5051 - categorical_accuracy: 0.8953 - val_loss: 0.5090 - val_categorical_accuracy: 0.8944\n",
            "Epoch 477/500\n",
            "109/109 [==============================] - 14s 120ms/step - loss: 0.5108 - categorical_accuracy: 0.8938 - val_loss: 0.5056 - val_categorical_accuracy: 0.8954\n",
            "Epoch 478/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5013 - categorical_accuracy: 0.8969 - val_loss: 0.5021 - val_categorical_accuracy: 0.8959\n",
            "Epoch 479/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.4998 - categorical_accuracy: 0.8969 - val_loss: 0.4891 - val_categorical_accuracy: 0.8986\n",
            "Epoch 480/500\n",
            "109/109 [==============================] - 14s 119ms/step - loss: 0.4981 - categorical_accuracy: 0.8973 - val_loss: 0.4857 - val_categorical_accuracy: 0.8991\n",
            "Epoch 481/500\n",
            "109/109 [==============================] - 14s 119ms/step - loss: 0.5017 - categorical_accuracy: 0.8957 - val_loss: 0.5170 - val_categorical_accuracy: 0.8942\n",
            "Epoch 482/500\n",
            "109/109 [==============================] - 14s 119ms/step - loss: 0.5019 - categorical_accuracy: 0.8960 - val_loss: 0.5097 - val_categorical_accuracy: 0.8938\n",
            "Epoch 483/500\n",
            "109/109 [==============================] - 14s 120ms/step - loss: 0.5061 - categorical_accuracy: 0.8947 - val_loss: 0.5127 - val_categorical_accuracy: 0.8943\n",
            "Epoch 484/500\n",
            "109/109 [==============================] - 14s 120ms/step - loss: 0.5011 - categorical_accuracy: 0.8963 - val_loss: 0.5167 - val_categorical_accuracy: 0.8928\n",
            "Epoch 485/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.4983 - categorical_accuracy: 0.8970 - val_loss: 0.4978 - val_categorical_accuracy: 0.8974\n",
            "Epoch 486/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5025 - categorical_accuracy: 0.8959 - val_loss: 0.5142 - val_categorical_accuracy: 0.8937\n",
            "Epoch 487/500\n",
            "109/109 [==============================] - 14s 118ms/step - loss: 0.5029 - categorical_accuracy: 0.8954 - val_loss: 0.4946 - val_categorical_accuracy: 0.8975\n",
            "Epoch 488/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.5030 - categorical_accuracy: 0.8955 - val_loss: 0.5174 - val_categorical_accuracy: 0.8937\n",
            "Epoch 489/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5087 - categorical_accuracy: 0.8941 - val_loss: 0.5101 - val_categorical_accuracy: 0.8937\n",
            "Epoch 490/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5139 - categorical_accuracy: 0.8938 - val_loss: 0.4965 - val_categorical_accuracy: 0.8966\n",
            "Epoch 491/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5057 - categorical_accuracy: 0.8946 - val_loss: 0.5030 - val_categorical_accuracy: 0.8962\n",
            "Epoch 492/500\n",
            "109/109 [==============================] - 13s 114ms/step - loss: 0.5041 - categorical_accuracy: 0.8956 - val_loss: 0.5045 - val_categorical_accuracy: 0.8956\n",
            "Epoch 493/500\n",
            "109/109 [==============================] - 13s 118ms/step - loss: 0.5037 - categorical_accuracy: 0.8957 - val_loss: 0.4961 - val_categorical_accuracy: 0.8978\n",
            "Epoch 494/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5051 - categorical_accuracy: 0.8957 - val_loss: 0.5002 - val_categorical_accuracy: 0.8968\n",
            "Epoch 495/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5041 - categorical_accuracy: 0.8961 - val_loss: 0.5012 - val_categorical_accuracy: 0.8958\n",
            "Epoch 496/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5056 - categorical_accuracy: 0.8947 - val_loss: 0.5135 - val_categorical_accuracy: 0.8955\n",
            "Epoch 497/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5079 - categorical_accuracy: 0.8950 - val_loss: 0.5073 - val_categorical_accuracy: 0.8942\n",
            "Epoch 498/500\n",
            "109/109 [==============================] - 13s 117ms/step - loss: 0.5028 - categorical_accuracy: 0.8956 - val_loss: 0.4942 - val_categorical_accuracy: 0.8977\n",
            "Epoch 499/500\n",
            "109/109 [==============================] - 13s 116ms/step - loss: 0.4948 - categorical_accuracy: 0.8972 - val_loss: 0.5049 - val_categorical_accuracy: 0.8963\n",
            "Epoch 500/500\n",
            "109/109 [==============================] - 13s 115ms/step - loss: 0.5094 - categorical_accuracy: 0.8947 - val_loss: 0.5002 - val_categorical_accuracy: 0.8969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SHLYHzn3Y8L",
        "outputId": "eb5d882e-862d-4094-c51d-1f6e2eef567c"
      },
      "source": [
        "# Testing on new translations\n",
        "\n",
        "for input_text, translation in test_data.take(1):\n",
        "    pred = np.argmax(model.predict(input_text), axis=-1)\n",
        "\n",
        "# French \n",
        "print(\"Input Sentence:\", end=\" \")\n",
        "for indice in input_text[2]:\n",
        "    if indice == 0:\n",
        "        break\n",
        "    print(indice_to_fr_token[indice.numpy()], end=\" \")\n",
        "\n",
        "# True\n",
        "print(\"\\nTrue Translation:\", end=\" \")\n",
        "for indice in np.argmax(translation, axis=-1)[2]:\n",
        "    if indice == 0:\n",
        "        break\n",
        "    print(indice_to_en_token[indice], end=\" \")\n",
        "\n",
        "# Pred\n",
        "print(\"\\nModel Translation:\", end=\" \")\n",
        "for indice in pred[2]:\n",
        "    if indice == 0:\n",
        "        break\n",
        "    print(indice_to_en_token[indice], end=\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sentence: L' argent ne nous rend pas nécessairement plus heureux . \n",
            "True Translation: Money does n't necessarily make you happier . \n",
            "Model Translation: Money did n't necessarily to you happier . "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "424otoV7oi8A"
      },
      "source": [
        "After 2 training steps, the model reached an accuracy of 0.89 on the validation set. Nevertheless, we still notice some weaknesses guessing the time used or translating the verbal group.\n",
        "\n",
        "A solution may be first to run the model on the whole dataset to increase the amount of training data, and then adapt the number of layers in our neural network."
      ]
    }
  ]
}